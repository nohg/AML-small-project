{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the small project data into Python\n",
    "\n",
    "This file will show how to read the data from the files `train.h5` and `test.h5` into Python, for training.\n",
    "The files are available at:\n",
    "\n",
    "<https://www.nbi.dk/~petersen/Teaching/ML2020/SmallProject/train.h5>\n",
    "\n",
    "<https://www.nbi.dk/~petersen/Teaching/ML2020/SmallProject/test.h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by opening the files and loading them into a Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(name):\n",
    "    with h5py.File(f'{name}.h5', 'r') as f:\n",
    "        return pandas.DataFrame(f[name][:])\n",
    "\n",
    "train = load_data('train')\n",
    "test  = load_data('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can verify the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data set: (162500, 166)\n",
      "Shape of test data set: (160651, 164)\n"
     ]
    }
   ],
   "source": [
    "print (f'Shape of training data set: {train.shape}')\n",
    "print (f'Shape of test data set: {test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the test set contains 2 columns less: `Truth` and `p_truth_E`.\n",
    "    \n",
    "Then we copy the variable list from the course website <https://www.nbi.dk/~petersen/Teaching/ML2020/SmallProject/VariableList.html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_variables = ['actualInteractionsPerCrossing', 'averageInteractionsPerCrossing', 'correctedActualMu', 'correctedAverageMu', 'correctedScaledActualMu', 'correctedScaledAverageMu', 'NvtxReco', 'p_nTracks', 'p_pt_track', 'p_eta', 'p_phi', 'p_charge', 'p_qOverP', 'p_z0', 'p_d0', 'p_sigmad0', 'p_d0Sig', 'p_EptRatio', 'p_dPOverP', 'p_z0theta', 'p_etaCluster', 'p_phiCluster', 'p_eCluster', 'p_rawEtaCluster', 'p_rawPhiCluster', 'p_rawECluster', 'p_eClusterLr0', 'p_eClusterLr1', 'p_eClusterLr2', 'p_eClusterLr3', 'p_etaClusterLr1', 'p_etaClusterLr2', 'p_phiClusterLr2', 'p_eAccCluster', 'p_f0Cluster', 'p_etaCalo', 'p_phiCalo', 'p_eTileGap3Cluster', 'p_cellIndexCluster', 'p_phiModCalo', 'p_etaModCalo', 'p_dPhiTH3', 'p_R12', 'p_fTG3', 'p_weta2', 'p_Reta', 'p_Rphi', 'p_Eratio', 'p_f1', 'p_f3', 'p_Rhad', 'p_Rhad1', 'p_deltaEta1', 'p_deltaPhiRescaled2', 'p_TRTPID', 'p_TRTTrackOccupancy', 'p_numberOfInnermostPixelHits', 'p_numberOfPixelHits', 'p_numberOfSCTHits', 'p_numberOfTRTHits', 'p_numberOfTRTXenonHits', 'p_chi2', 'p_ndof', 'p_SharedMuonTrack', 'p_E7x7_Lr2', 'p_E7x7_Lr3', 'p_E_Lr0_HiG', 'p_E_Lr0_LowG', 'p_E_Lr0_MedG', 'p_E_Lr1_HiG', 'p_E_Lr1_LowG', 'p_E_Lr1_MedG', 'p_E_Lr2_HiG', 'p_E_Lr2_LowG', 'p_E_Lr2_MedG', 'p_E_Lr3_HiG', 'p_E_Lr3_LowG', 'p_E_Lr3_MedG', 'p_ambiguityType', 'p_asy1', 'p_author', 'p_barys1', 'p_core57cellsEnergyCorrection', 'p_deltaEta0', 'p_deltaEta2', 'p_deltaEta3', 'p_deltaPhi0', 'p_deltaPhi1', 'p_deltaPhi2', 'p_deltaPhi3', 'p_deltaPhiFromLastMeasurement', 'p_deltaPhiRescaled0', 'p_deltaPhiRescaled1', 'p_deltaPhiRescaled3', 'p_e1152', 'p_e132', 'p_e235', 'p_e255', 'p_e2ts1', 'p_ecore', 'p_emins1', 'p_etconeCorrBitset', 'p_ethad', 'p_ethad1', 'p_f1core', 'p_f3core', 'p_maxEcell_energy', 'p_maxEcell_gain', 'p_maxEcell_time', 'p_maxEcell_x', 'p_maxEcell_y', 'p_maxEcell_z', 'p_nCells_Lr0_HiG', 'p_nCells_Lr0_LowG', 'p_nCells_Lr0_MedG', 'p_nCells_Lr1_HiG', 'p_nCells_Lr1_LowG', 'p_nCells_Lr1_MedG', 'p_nCells_Lr2_HiG', 'p_nCells_Lr2_LowG', 'p_nCells_Lr2_MedG', 'p_nCells_Lr3_HiG', 'p_nCells_Lr3_LowG', 'p_nCells_Lr3_MedG', 'p_pos', 'p_pos7', 'p_poscs1', 'p_poscs2', 'p_ptconeCorrBitset', 'p_ptconecoreTrackPtrCorrection', 'p_r33over37allcalo', 'p_topoetconeCorrBitset', 'p_topoetconecoreConeEnergyCorrection', 'p_topoetconecoreConeSCEnergyCorrection', 'p_weta1', 'p_widths1', 'p_widths2', 'p_wtots1', 'p_e233', 'p_e237', 'p_e277', 'p_e2tsts1', 'p_ehad1', 'p_emaxs1', 'p_fracs1', 'p_DeltaE', 'p_E3x5_Lr0', 'p_E3x5_Lr1', 'p_E3x5_Lr2', 'p_E3x5_Lr3', 'p_E5x7_Lr0', 'p_E5x7_Lr1', 'p_E5x7_Lr2', 'p_E5x7_Lr3', 'p_E7x11_Lr0', 'p_E7x11_Lr1', 'p_E7x11_Lr2', 'p_E7x11_Lr3', 'p_E7x7_Lr0', 'p_E7x7_Lr1' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we divide the training data into data (`X`) and labels (`y`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (162500, 160)\n",
      "Shape of y: (162500,)\n"
     ]
    }
   ],
   "source": [
    "X = train[all_variables]\n",
    "y = train['Truth']\n",
    "\n",
    "print (f'Shape of X: {X.shape}')\n",
    "print (f'Shape of y: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualInteractionsPerCrossing</th>\n",
       "      <th>averageInteractionsPerCrossing</th>\n",
       "      <th>correctedActualMu</th>\n",
       "      <th>correctedAverageMu</th>\n",
       "      <th>correctedScaledActualMu</th>\n",
       "      <th>correctedScaledAverageMu</th>\n",
       "      <th>NvtxReco</th>\n",
       "      <th>p_nTracks</th>\n",
       "      <th>p_pt_track</th>\n",
       "      <th>p_eta</th>\n",
       "      <th>...</th>\n",
       "      <th>p_E5x7_Lr0</th>\n",
       "      <th>p_E5x7_Lr1</th>\n",
       "      <th>p_E5x7_Lr2</th>\n",
       "      <th>p_E5x7_Lr3</th>\n",
       "      <th>p_E7x11_Lr0</th>\n",
       "      <th>p_E7x11_Lr1</th>\n",
       "      <th>p_E7x11_Lr2</th>\n",
       "      <th>p_E7x11_Lr3</th>\n",
       "      <th>p_E7x7_Lr0</th>\n",
       "      <th>p_E7x7_Lr1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>42011.792969</td>\n",
       "      <td>1.834715</td>\n",
       "      <td>...</td>\n",
       "      <td>215.588013</td>\n",
       "      <td>43402.332031</td>\n",
       "      <td>74045.820312</td>\n",
       "      <td>337.980713</td>\n",
       "      <td>273.708801</td>\n",
       "      <td>43091.683594</td>\n",
       "      <td>74447.539062</td>\n",
       "      <td>470.177124</td>\n",
       "      <td>273.708801</td>\n",
       "      <td>43091.683594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   actualInteractionsPerCrossing  averageInteractionsPerCrossing  \\\n",
       "0                           26.5                            26.5   \n",
       "\n",
       "   correctedActualMu  correctedAverageMu  correctedScaledActualMu  \\\n",
       "0               26.5                26.5                     26.5   \n",
       "\n",
       "   correctedScaledAverageMu  NvtxReco  p_nTracks    p_pt_track     p_eta  ...  \\\n",
       "0                      26.5        18          3  42011.792969  1.834715  ...   \n",
       "\n",
       "   p_E5x7_Lr0    p_E5x7_Lr1    p_E5x7_Lr2  p_E5x7_Lr3  p_E7x11_Lr0  \\\n",
       "0  215.588013  43402.332031  74045.820312  337.980713   273.708801   \n",
       "\n",
       "    p_E7x11_Lr1   p_E7x11_Lr2  p_E7x11_Lr3  p_E7x7_Lr0    p_E7x7_Lr1  \n",
       "0  43091.683594  74447.539062   470.177124  273.708801  43091.683594  \n",
       "\n",
       "[1 rows x 160 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_count = y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion: 2.96 : 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Proportion:', round(target_count[1] / target_count[0], 2), ': 1')\n",
    "\n",
    "target_count.plot(kind='bar', title='Count (target)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eventNumber                       0\n",
       "runNumber                         0\n",
       "actualInteractionsPerCrossing     0\n",
       "averageInteractionsPerCrossing    0\n",
       "correctedActualMu                 0\n",
       "                                 ..\n",
       "p_E7x11_Lr2                       0\n",
       "p_E7x11_Lr3                       0\n",
       "p_E7x7_Lr0                        0\n",
       "p_E7x7_Lr1                        0\n",
       "index                             0\n",
       "Length: 166, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No nulls\n",
    "### Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_X = deepcopy(X) \n",
    "# This loop transforms every variable _independently_ \n",
    "for variable in X.columns:     \n",
    "    transformed_X[variable] = RobustScaler().fit_transform(np.array(transformed_X[variable]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select k Best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niallgray/opt/miniconda3/envs/aml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:301: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/niallgray/opt/miniconda3/envs/aml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:301: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/niallgray/opt/miniconda3/envs/aml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:306: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(162500, 25)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_25 = SelectKBest(score_func=f_regression, k=25).fit_transform(X, y)\n",
    "X_25.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian optimisation of hyperparameters and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GBC_CrossValidation(n_estimators, learning_rate, max_depth, data, targets):\n",
    "    \"\"\"Decision Tree cross validation.\n",
    "       Fits a Decision Tree with the given paramaters to the target \n",
    "       given data, calculated a CV accuracy score and returns the mean.\n",
    "       The goal is to find combinations\n",
    "       that maximize the accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    estimator = GradientBoostingClassifier(n_estimators=n_estimators, learning_rate=learning_rate, \n",
    "                                 max_depth=max_depth, random_state=0)\n",
    "    \n",
    "    cval = cross_val_score(estimator, data, targets, scoring='accuracy', cv=5)\n",
    "    \n",
    "    return cval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_GBC(data, targets, pars, n_iter=5):\n",
    "    \"\"\"Apply Bayesian Optimization to Decision Tree parameters.\"\"\"\n",
    "    \n",
    "    def crossval_wrapper(n_estimators, learning_rate, max_depth):\n",
    "        \"\"\"Wrapper of Decision Tree cross validation. \n",
    "           max_depth and n_estimators\n",
    "           are cast to integer before we pass them along.\n",
    "        \"\"\"\n",
    "        return GBC_CrossValidation(n_estimators=int(n_estimators), \n",
    "                                            learning_rate=learning_rate, \n",
    "                                            max_depth=int(max_depth),\n",
    "                                            data=data, \n",
    "                                            targets=targets)\n",
    "\n",
    "    optimizer = BayesianOptimization(f=crossval_wrapper, \n",
    "                                     pbounds=pars, \n",
    "                                     random_state=42, \n",
    "                                     verbose=2)\n",
    "    optimizer.maximize(init_points=4, n_iter=n_iter)\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learni... | max_depth | n_esti... |\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0.37460266483547777, 4.802857225639665, 379.3972738151323)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a341a82c2565>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                   }\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m BayesianOptimization = optimize_GBC(X_25, \n\u001b[0m\u001b[1;32m      7\u001b[0m                                              \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                              \u001b[0mparameters_BayesianOptimization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-cc2e07d4396f>\u001b[0m in \u001b[0;36moptimize_GBC\u001b[0;34m(data, targets, pars, n_iter)\u001b[0m\n\u001b[1;32m     17\u001b[0m                                      \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                      verbose=2)\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZATION_END\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-cc2e07d4396f>\u001b[0m in \u001b[0;36mcrossval_wrapper\u001b[0;34m(n_estimators, learning_rate, max_depth)\u001b[0m\n\u001b[1;32m      7\u001b[0m            \u001b[0mare\u001b[0m \u001b[0mcast\u001b[0m \u001b[0mto\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mbefore\u001b[0m \u001b[0mwe\u001b[0m \u001b[0;32mpass\u001b[0m \u001b[0mthem\u001b[0m \u001b[0malong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \"\"\"\n\u001b[0;32m----> 9\u001b[0;31m         return GBC_CrossValidation(n_estimators=int(n_estimators), \n\u001b[0m\u001b[1;32m     10\u001b[0m                                             \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                             \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-375f0d47a8fe>\u001b[0m in \u001b[0;36mGBC_CrossValidation\u001b[0;34m(n_estimators, learning_rate, max_depth, data, targets)\u001b[0m\n\u001b[1;32m     10\u001b[0m                                  max_depth=max_depth, random_state=0)\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mcval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[1;32m    441\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    244\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[1;32m    245\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[0;32m--> 246\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    247\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    248\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         n_stages = self._fit_stages(\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             sample_weight_val, begin_at_stage, monitor)\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0;31m# fit next stage of trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[1;32m    562\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                 random_state, X_csc, X_csr)\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0m\u001b[1;32m    215\u001b[0m                      check_input=False)\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \"\"\"\n\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1248\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    387\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parameters_BayesianOptimization = {\"learning_rate\": (0.0001, 1), \n",
    "                                   \"max_depth\": (1, 5),\n",
    "                                   \"n_estimators\": (50,500)\n",
    "                                  }\n",
    "\n",
    "BayesianOptimization = optimize_GBC(X_25, \n",
    "                                             y, \n",
    "                                             parameters_BayesianOptimization, \n",
    "                                             n_iter=5)\n",
    "print(BayesianOptimization.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation on result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'property' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-eb7a14fb0c09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m gbc = GradientBoostingClassifier(n_estimators=int(BayesianOptimization.max['params']['n_estimators']), \n\u001b[0m\u001b[1;32m      2\u001b[0m                                  \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                  \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_depth'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                  random_state=0)\n\u001b[1;32m      5\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgbc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'property' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators=int(BayesianOptimization.max['params']['n_estimators']), \n",
    "                                 learning_rate=BayesianOptimization.max['params']['learning_rate'], \n",
    "                                 max_depth=BayesianOptimization.max['params']['max_depth'], \n",
    "                                 random_state=0)\n",
    "scores = cross_val_score(gbc, features_data, targets_data, cv=5, scoring='f1') \n",
    "print(f\"{scores.mean():.4f} accuracy with a standard deviation of {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.945 (0.002)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "data_train = lgb.Dataset(X_25, label=y)\n",
    "params = {'objective': 'binary',\n",
    "          'boosting_type': 'gbdt',\n",
    "          'metric': 'binary_logloss',\n",
    "          'learning_rate': 0.01,\n",
    "          'num_leaves': 10,\n",
    "          'max_depth': 10,\n",
    "          'min_data': 10,\n",
    "          'verbose': 0,\n",
    "          'force_col_wise': True}\n",
    "\n",
    "#lgb_clf = lgb.train(params, train_set=data_train, num_boost_round=300)\n",
    "#lgb.cv(params, data_train, num_boost_round=300, nfold=5)\n",
    "\n",
    "\n",
    "# y_pred = np.around(lgb_clf.predict(test_X))\n",
    "# acc = accuracy_score(y_pred, test_y)\n",
    "# print(f\"Train accuracy: {acc*100.0:.2f}%\")\n",
    "\n",
    "# evaluate the model\n",
    "\n",
    "model = LGBMClassifier()\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-19 12:01:57,740]\u001b[0m A new study created in memory with name: no-name-922108c8-c512-4b33-932e-6ec60d3607fd\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "from optuna.pruners import MedianPruner\n",
    "import lightgbm as lgb\n",
    "\n",
    "#%%\n",
    "\n",
    "lgb_data_train = lgb.Dataset(X_25, label=y)\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    boosting_types = [\"gbdt\", \"rf\", \"dart\"]\n",
    "    boosting_type = trial.suggest_categorical(\"boosting_type\", boosting_types)\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"boosting\": boosting_type,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 63),\n",
    "        \"min_child_weight\": trial.suggest_loguniform(\"min_child_weight\", 1e-5, 10),\n",
    "        \"scale_pos_weight\": trial.suggest_uniform(\"scale_pos_weight\", 10.0, 30.0),\n",
    "    }\n",
    "\n",
    "    N_iterations_max = 10_000\n",
    "    early_stopping_rounds = 50\n",
    "\n",
    "    if boosting_type == \"dart\":\n",
    "        N_iterations_max = 100\n",
    "        early_stopping_rounds = None\n",
    "\n",
    "    cv_res = lgb.cv(\n",
    "        params,\n",
    "        lgb_data_train,\n",
    "        num_boost_round=N_iterations_max,\n",
    "        early_stopping_rounds=early_stopping_rounds,\n",
    "        verbose_eval=False,\n",
    "        seed=42,\n",
    "        callbacks=[LightGBMPruningCallback(trial, \"auc\")],\n",
    "    )\n",
    "\n",
    "    num_boost_round = len(cv_res[\"auc-mean\"])\n",
    "    trial.set_user_attr(\"num_boost_round\", num_boost_round)\n",
    "    return cv_res[\"auc-mean\"][-1]\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=TPESampler(seed=42),\n",
    "    pruner=MedianPruner(n_warmup_steps=50),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niallgray/opt/miniconda3/envs/aml/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5deb1f3438f49eabcff4ec6015628e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 97196, number of negative: 32804\n",
      "\u001b[33m[W 2021-05-19 12:01:59,545]\u001b[0m Trial 0 failed because of the following error: LightGBMError('Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /tmp/pip-req-build-12fs9jsp/compile/src/boosting/rf.hpp, line 35 .\\n')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/niallgray/opt/miniconda3/envs/aml/lib/python3.8/site-packages/optuna/_optimize.py\", line 217, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"<ipython-input-18-205b099d44e5>\", line 35, in objective\n",
      "    cv_res = lgb.cv(\n",
      "  File \"/Users/niallgray/opt/miniconda3/envs/aml/lib/python3.8/site-packages/lightgbm/engine.py\", line 557, in cv\n",
      "    cvfolds = _make_n_folds(train_set, folds=folds, nfold=nfold,\n",
      "  File \"/Users/niallgray/opt/miniconda3/envs/aml/lib/python3.8/site-packages/lightgbm/engine.py\", line 367, in _make_n_folds\n",
      "    cvbooster = Booster(tparam, train_set)\n",
      "  File \"/Users/niallgray/opt/miniconda3/envs/aml/lib/python3.8/site-packages/lightgbm/basic.py\", line 2234, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/niallgray/opt/miniconda3/envs/aml/lib/python3.8/site-packages/lightgbm/basic.py\", line 110, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /tmp/pip-req-build-12fs9jsp/compile/src/boosting/rf.hpp, line 35 .\n",
      "\u001b[0m\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /tmp/pip-req-build-12fs9jsp/compile/src/boosting/rf.hpp, line 35 .\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b2f2701dc7e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    398\u001b[0m             )\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAIL\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-205b099d44e5>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mearly_stopping_rounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     cv_res = lgb.cv(\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mlgb_data_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, fpreproc, verbose_eval, show_stdv, seed, callbacks, eval_train_metric, return_cvbooster)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m     cvfolds = _make_n_folds(train_set, folds=folds, nfold=nfold,\n\u001b[0m\u001b[1;32m    558\u001b[0m                             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpreproc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfpreproc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m                             \u001b[0mstratified\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratified\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36m_make_n_folds\u001b[0;34m(full_data, folds, nfold, params, seed, fpreproc, stratified, shuffle, eval_train_metric)\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mtparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mcvbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0meval_train_metric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0mcvbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[1;32m   2232\u001b[0m             \u001b[0mparams_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_dict_to_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2233\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2234\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterCreate(\n\u001b[0m\u001b[1;32m   2235\u001b[0m                 \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2236\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \"\"\"\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLightGBMError\u001b[0m: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /tmp/pip-req-build-12fs9jsp/compile/src/boosting/rf.hpp, line 35 .\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=100, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-19 12:13:46,199]\u001b[0m A new study created in memory with name: no-name-d398fa54-9d61-4b88-ac40-155142b52352\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.200096:   0%|          | 0/7 [00:06<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.200096:  14%|#4        | 1/7 [00:06<00:39,  6.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-05-19 12:13:52,863]\u001b[0m Trial 0 finished with value: 0.2000957907245414 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.2000957907245414.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [03:39<?, ?it/s]9,  6.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [02:36<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.200055:  14%|#4        | 1/7 [00:12<00:39,  6.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.200055:  29%|##8       | 2/7 [00:12<00:32,  6.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-05-19 12:13:59,190]\u001b[0m Trial 1 finished with value: 0.2000551216156724 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 0.2000551216156724.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.200055:  29%|##8       | 2/7 [00:12<00:32,  6.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.200055:  29%|##8       | 2/7 [00:20<00:32,  6.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.200055:  43%|####2     | 3/7 [00:20<00:27,  6.86s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-05-19 12:14:06,523]\u001b[0m Trial 2 finished with value: 0.20012291617627329 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 0.2000551216156724.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.200055:  43%|####2     | 3/7 [00:20<00:27,  6.86s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.199965:  43%|####2     | 3/7 [00:27<00:27,  6.86s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.199965:  57%|#####7    | 4/7 [00:27<00:21,  7.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-05-19 12:14:14,214]\u001b[0m Trial 3 finished with value: 0.1999652085800593 and parameters: {'feature_fraction': 0.6}. Best is trial 3 with value: 0.1999652085800593.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.199965:  57%|#####7    | 4/7 [00:28<00:21,  7.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.199827:  57%|#####7    | 4/7 [00:37<00:21,  7.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.199827:  71%|#######1  | 5/7 [00:37<00:16,  8.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-05-19 12:14:24,076]\u001b[0m Trial 4 finished with value: 0.19982746594776113 and parameters: {'feature_fraction': 0.7}. Best is trial 4 with value: 0.19982746594776113.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.199827:  71%|#######1  | 5/7 [00:37<00:16,  8.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.199827:  71%|#######1  | 5/7 [00:46<00:16,  8.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.199827:  86%|########5 | 6/7 [00:46<00:08,  8.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-05-19 12:14:33,044]\u001b[0m Trial 5 finished with value: 0.20008238850620827 and parameters: {'feature_fraction': 0.4}. Best is trial 4 with value: 0.19982746594776113.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.199827:  86%|########5 | 6/7 [00:46<00:08,  8.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.199827:  86%|########5 | 6/7 [00:54<00:08,  8.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.199827: 100%|##########| 7/7 [00:54<00:00,  8.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-05-19 12:14:41,148]\u001b[0m Trial 6 finished with value: 0.20000237447504668 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 4 with value: 0.19982746594776113.\u001b[0m\n",
      "feature_fraction, val_score: 0.199827: 100%|##########| 7/7 [00:54<00:00,  7.85s/it]\n",
      "num_leaves, val_score: 0.199827:   5%|5         | 1/20 [00:10<03:26, 10.88s/it]\u001b[32m[I 2021-05-19 12:14:52,092]\u001b[0m Trial 7 finished with value: 0.200555703499277 and parameters: {'num_leaves': 65}. Best is trial 7 with value: 0.200555703499277.\u001b[0m\n",
      "num_leaves, val_score: 0.199827:  10%|#         | 2/20 [00:22<03:28, 11.57s/it]\u001b[32m[I 2021-05-19 12:15:04,137]\u001b[0m Trial 8 finished with value: 0.2011941777823376 and parameters: {'num_leaves': 114}. Best is trial 7 with value: 0.200555703499277.\u001b[0m\n",
      "num_leaves, val_score: 0.199827:  15%|#5        | 3/20 [00:30<02:48,  9.90s/it]\u001b[32m[I 2021-05-19 12:15:12,043]\u001b[0m Trial 9 finished with value: 0.2015303068816959 and parameters: {'num_leaves': 116}. Best is trial 7 with value: 0.200555703499277.\u001b[0m\n",
      "num_leaves, val_score: 0.199827:  20%|##        | 4/20 [00:36<02:10,  8.18s/it]\u001b[32m[I 2021-05-19 12:15:17,585]\u001b[0m Trial 10 finished with value: 0.19984035517210633 and parameters: {'num_leaves': 28}. Best is trial 10 with value: 0.19984035517210633.\u001b[0m\n",
      "num_leaves, val_score: 0.199827:  25%|##5       | 5/20 [00:47<02:19,  9.33s/it]\u001b[32m[I 2021-05-19 12:15:28,950]\u001b[0m Trial 11 finished with value: 0.2019600633205194 and parameters: {'num_leaves': 162}. Best is trial 10 with value: 0.19984035517210633.\u001b[0m\n",
      "num_leaves, val_score: 0.199827:  30%|###       | 6/20 [00:53<01:55,  8.22s/it]\u001b[32m[I 2021-05-19 12:15:35,024]\u001b[0m Trial 12 finished with value: 0.20017950610148005 and parameters: {'num_leaves': 44}. Best is trial 10 with value: 0.19984035517210633.\u001b[0m\n",
      "num_leaves, val_score: 0.199827:  35%|###5      | 7/20 [01:02<01:47,  8.27s/it]\u001b[32m[I 2021-05-19 12:15:43,396]\u001b[0m Trial 13 finished with value: 0.20200903058296774 and parameters: {'num_leaves': 154}. Best is trial 10 with value: 0.19984035517210633.\u001b[0m\n",
      "num_leaves, val_score: 0.199827:  40%|####      | 8/20 [01:12<01:45,  8.82s/it]\u001b[32m[I 2021-05-19 12:15:53,390]\u001b[0m Trial 14 finished with value: 0.20337411752443516 and parameters: {'num_leaves': 236}. Best is trial 10 with value: 0.19984035517210633.\u001b[0m\n",
      "num_leaves, val_score: 0.199827:  45%|####5     | 9/20 [01:18<01:29,  8.14s/it]\u001b[32m[I 2021-05-19 12:16:00,043]\u001b[0m Trial 15 finished with value: 0.20091791136983375 and parameters: {'num_leaves': 82}. Best is trial 10 with value: 0.19984035517210633.\u001b[0m\n",
      "num_leaves, val_score: 0.199827:  50%|#####     | 10/20 [01:27<01:21,  8.18s/it]\u001b[32m[I 2021-05-19 12:16:08,321]\u001b[0m Trial 16 finished with value: 0.20182674197355865 and parameters: {'num_leaves': 136}. Best is trial 10 with value: 0.19984035517210633.\u001b[0m\n",
      "num_leaves, val_score: 0.199827:  55%|#####5    | 11/20 [01:40<01:27,  9.76s/it]\u001b[32m[I 2021-05-19 12:16:21,661]\u001b[0m Trial 17 finished with value: 0.20306356449904384 and parameters: {'num_leaves': 220}. Best is trial 10 with value: 0.19984035517210633.\u001b[0m\n",
      "num_leaves, val_score: 0.199827:  60%|######    | 12/20 [01:53<01:26, 10.76s/it]\u001b[32m[I 2021-05-19 12:16:34,707]\u001b[0m Trial 18 finished with value: 0.2007696422077865 and parameters: {'num_leaves': 4}. Best is trial 10 with value: 0.19984035517210633.\u001b[0m\n",
      "num_leaves, val_score: 0.199827:  65%|######5   | 13/20 [01:59<01:04,  9.23s/it]\u001b[32m[I 2021-05-19 12:16:40,428]\u001b[0m Trial 19 finished with value: 0.20233786117947186 and parameters: {'num_leaves': 5}. Best is trial 10 with value: 0.19984035517210633.\u001b[0m\n",
      "num_leaves, val_score: 0.199827:  70%|#######   | 14/20 [02:04<00:48,  8.09s/it]\u001b[32m[I 2021-05-19 12:16:45,883]\u001b[0m Trial 20 finished with value: 0.2000730433649954 and parameters: {'num_leaves': 43}. Best is trial 10 with value: 0.19984035517210633.\u001b[0m\n",
      "num_leaves, val_score: 0.199827:  75%|#######5  | 15/20 [02:10<00:36,  7.39s/it]\u001b[32m[I 2021-05-19 12:16:51,648]\u001b[0m Trial 21 finished with value: 0.20000367824247955 and parameters: {'num_leaves': 34}. Best is trial 10 with value: 0.19984035517210633.\u001b[0m\n",
      "num_leaves, val_score: 0.199827:  80%|########  | 16/20 [02:21<00:33,  8.48s/it]\u001b[32m[I 2021-05-19 12:17:02,673]\u001b[0m Trial 22 finished with value: 0.21092200308703676 and parameters: {'num_leaves': 2}. Best is trial 10 with value: 0.19984035517210633.\u001b[0m\n",
      "num_leaves, val_score: 0.199827:  85%|########5 | 17/20 [02:27<00:22,  7.62s/it]\u001b[32m[I 2021-05-19 12:17:08,292]\u001b[0m Trial 23 finished with value: 0.20016630229250632 and parameters: {'num_leaves': 33}. Best is trial 10 with value: 0.19984035517210633.\u001b[0m\n",
      "num_leaves, val_score: 0.199827:  90%|######### | 18/20 [02:34<00:14,  7.50s/it]\u001b[32m[I 2021-05-19 12:17:15,500]\u001b[0m Trial 24 finished with value: 0.201008803044702 and parameters: {'num_leaves': 85}. Best is trial 10 with value: 0.19984035517210633.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.199827:  95%|#########5| 19/20 [02:41<00:07,  7.43s/it]\u001b[32m[I 2021-05-19 12:17:22,772]\u001b[0m Trial 25 finished with value: 0.20014746018577764 and parameters: {'num_leaves': 25}. Best is trial 10 with value: 0.19984035517210633.\u001b[0m\n",
      "num_leaves, val_score: 0.199827: 100%|##########| 20/20 [02:52<00:00,  8.56s/it]\u001b[32m[I 2021-05-19 12:17:33,981]\u001b[0m Trial 26 finished with value: 0.2025424243368387 and parameters: {'num_leaves': 194}. Best is trial 10 with value: 0.19984035517210633.\u001b[0m\n",
      "num_leaves, val_score: 0.199827: 100%|##########| 20/20 [02:52<00:00,  8.64s/it]\n",
      "bagging, val_score: 0.199827:  10%|#         | 1/10 [00:05<00:52,  5.87s/it]\u001b[32m[I 2021-05-19 12:17:39,853]\u001b[0m Trial 27 finished with value: 0.20086109937049687 and parameters: {'bagging_fraction': 0.4581668886199648, 'bagging_freq': 1}. Best is trial 27 with value: 0.20086109937049687.\u001b[0m\n",
      "bagging, val_score: 0.199827:  20%|##        | 2/10 [00:12<00:49,  6.19s/it]\u001b[32m[I 2021-05-19 12:17:46,273]\u001b[0m Trial 28 finished with value: 0.20001086420511294 and parameters: {'bagging_fraction': 0.9690448217394018, 'bagging_freq': 1}. Best is trial 28 with value: 0.20001086420511294.\u001b[0m\n",
      "bagging, val_score: 0.199827:  30%|###       | 3/10 [00:19<00:45,  6.46s/it]\u001b[32m[I 2021-05-19 12:17:53,057]\u001b[0m Trial 29 finished with value: 0.20040548644108838 and parameters: {'bagging_fraction': 0.6826032024145492, 'bagging_freq': 5}. Best is trial 28 with value: 0.20001086420511294.\u001b[0m\n",
      "bagging, val_score: 0.199827:  40%|####      | 4/10 [00:26<00:41,  6.95s/it]\u001b[32m[I 2021-05-19 12:18:00,766]\u001b[0m Trial 30 finished with value: 0.20038128777868613 and parameters: {'bagging_fraction': 0.6595437870158062, 'bagging_freq': 4}. Best is trial 28 with value: 0.20001086420511294.\u001b[0m\n",
      "bagging, val_score: 0.199827:  50%|#####     | 5/10 [00:36<00:40,  8.02s/it]\u001b[32m[I 2021-05-19 12:18:10,664]\u001b[0m Trial 31 finished with value: 0.20017287185505186 and parameters: {'bagging_fraction': 0.8153075611216904, 'bagging_freq': 6}. Best is trial 28 with value: 0.20001086420511294.\u001b[0m\n",
      "bagging, val_score: 0.199827:  60%|######    | 6/10 [00:46<00:33,  8.47s/it]\u001b[32m[I 2021-05-19 12:18:20,027]\u001b[0m Trial 32 finished with value: 0.19992291758984249 and parameters: {'bagging_fraction': 0.9403563303810422, 'bagging_freq': 1}. Best is trial 32 with value: 0.19992291758984249.\u001b[0m\n",
      "bagging, val_score: 0.199827:  70%|#######   | 7/10 [00:53<00:24,  8.28s/it]\u001b[32m[I 2021-05-19 12:18:27,920]\u001b[0m Trial 33 finished with value: 0.20063484801788115 and parameters: {'bagging_fraction': 0.5341539320360922, 'bagging_freq': 4}. Best is trial 32 with value: 0.19992291758984249.\u001b[0m\n",
      "bagging, val_score: 0.199827:  80%|########  | 8/10 [01:02<00:16,  8.30s/it]\u001b[32m[I 2021-05-19 12:18:36,254]\u001b[0m Trial 34 finished with value: 0.20008087894763182 and parameters: {'bagging_fraction': 0.759588856183808, 'bagging_freq': 6}. Best is trial 32 with value: 0.19992291758984249.\u001b[0m\n",
      "bagging, val_score: 0.199827:  90%|######### | 9/10 [01:11<00:08,  8.52s/it]\u001b[32m[I 2021-05-19 12:18:45,262]\u001b[0m Trial 35 finished with value: 0.20020543930831444 and parameters: {'bagging_fraction': 0.7543695586679275, 'bagging_freq': 2}. Best is trial 32 with value: 0.19992291758984249.\u001b[0m\n",
      "bagging, val_score: 0.199827: 100%|##########| 10/10 [01:21<00:00,  9.10s/it]\u001b[32m[I 2021-05-19 12:18:55,647]\u001b[0m Trial 36 finished with value: 0.20004823628464471 and parameters: {'bagging_fraction': 0.9538668320399457, 'bagging_freq': 7}. Best is trial 32 with value: 0.19992291758984249.\u001b[0m\n",
      "bagging, val_score: 0.199827: 100%|##########| 10/10 [01:21<00:00,  8.17s/it]\n",
      "feature_fraction_stage2, val_score: 0.199827:  17%|#6        | 1/6 [00:08<00:42,  8.43s/it]\u001b[32m[I 2021-05-19 12:19:04,095]\u001b[0m Trial 37 finished with value: 0.19999582083507425 and parameters: {'feature_fraction': 0.62}. Best is trial 37 with value: 0.19999582083507425.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.199827:  33%|###3      | 2/6 [00:17<00:35,  8.93s/it]\u001b[32m[I 2021-05-19 12:19:13,381]\u001b[0m Trial 38 finished with value: 0.19994966789773425 and parameters: {'feature_fraction': 0.748}. Best is trial 38 with value: 0.19994966789773425.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.199827:  50%|#####     | 3/6 [00:25<00:25,  8.43s/it]\u001b[32m[I 2021-05-19 12:19:21,208]\u001b[0m Trial 39 finished with value: 0.19999582083507425 and parameters: {'feature_fraction': 0.652}. Best is trial 38 with value: 0.19994966789773425.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.199827:  67%|######6   | 4/6 [00:32<00:15,  7.68s/it]\u001b[32m[I 2021-05-19 12:19:27,750]\u001b[0m Trial 40 finished with value: 0.2001783938663418 and parameters: {'feature_fraction': 0.6839999999999999}. Best is trial 38 with value: 0.19994966789773425.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.199827:  83%|########3 | 5/6 [00:39<00:07,  7.66s/it]\u001b[32m[I 2021-05-19 12:19:35,355]\u001b[0m Trial 41 finished with value: 0.19982746594776116 and parameters: {'feature_fraction': 0.716}. Best is trial 41 with value: 0.19982746594776116.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.199827: 100%|##########| 6/6 [00:46<00:00,  7.34s/it]\u001b[32m[I 2021-05-19 12:19:42,075]\u001b[0m Trial 42 finished with value: 0.19994966789773425 and parameters: {'feature_fraction': 0.7799999999999999}. Best is trial 41 with value: 0.19982746594776116.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.199827: 100%|##########| 6/6 [00:46<00:00,  7.74s/it]\n",
      "regularization_factors, val_score: 0.199827:   5%|5         | 1/20 [00:08<02:39,  8.38s/it]\u001b[32m[I 2021-05-19 12:19:50,467]\u001b[0m Trial 43 finished with value: 0.200021393401698 and parameters: {'lambda_l1': 0.0009609261724650923, 'lambda_l2': 3.602341693385174e-05}. Best is trial 43 with value: 0.200021393401698.\u001b[0m\n",
      "regularization_factors, val_score: 0.199558:  10%|#         | 2/20 [00:17<02:33,  8.54s/it]\u001b[32m[I 2021-05-19 12:19:59,114]\u001b[0m Trial 44 finished with value: 0.19955770159564754 and parameters: {'lambda_l1': 0.13312300660228163, 'lambda_l2': 4.017136619375846}. Best is trial 44 with value: 0.19955770159564754.\u001b[0m\n",
      "regularization_factors, val_score: 0.199558:  15%|#5        | 3/20 [00:27<02:37,  9.29s/it]\u001b[32m[I 2021-05-19 12:20:09,293]\u001b[0m Trial 45 finished with value: 0.19988735716593808 and parameters: {'lambda_l1': 1.6810476739248712e-08, 'lambda_l2': 0.00014937035592114386}. Best is trial 44 with value: 0.19955770159564754.\u001b[0m\n",
      "regularization_factors, val_score: 0.199549:  20%|##        | 4/20 [00:40<02:51, 10.71s/it]\u001b[32m[I 2021-05-19 12:20:22,185]\u001b[0m Trial 46 finished with value: 0.19954896396241215 and parameters: {'lambda_l1': 0.13859331666959512, 'lambda_l2': 4.509854262894503}. Best is trial 46 with value: 0.19954896396241215.\u001b[0m\n",
      "regularization_factors, val_score: 0.199549:  25%|##5       | 5/20 [00:46<02:19,  9.32s/it]\u001b[32m[I 2021-05-19 12:20:29,045]\u001b[0m Trial 47 finished with value: 0.19995016767584042 and parameters: {'lambda_l1': 0.0011869374738350893, 'lambda_l2': 0.005520027800527286}. Best is trial 46 with value: 0.19954896396241215.\u001b[0m\n",
      "regularization_factors, val_score: 0.199549:  30%|###       | 6/20 [00:56<02:10,  9.30s/it]\u001b[32m[I 2021-05-19 12:20:38,299]\u001b[0m Trial 48 finished with value: 0.1997664436290535 and parameters: {'lambda_l1': 0.10706180872023628, 'lambda_l2': 7.50652467437549e-06}. Best is trial 46 with value: 0.19954896396241215.\u001b[0m\n",
      "regularization_factors, val_score: 0.199549:  35%|###5      | 7/20 [01:04<01:57,  9.03s/it]\u001b[32m[I 2021-05-19 12:20:46,769]\u001b[0m Trial 49 finished with value: 0.19986189197771007 and parameters: {'lambda_l1': 6.113433953209287e-08, 'lambda_l2': 0.0008355077052801332}. Best is trial 46 with value: 0.19954896396241215.\u001b[0m\n",
      "regularization_factors, val_score: 0.199549:  40%|####      | 8/20 [01:12<01:44,  8.68s/it]\u001b[32m[I 2021-05-19 12:20:54,692]\u001b[0m Trial 50 finished with value: 0.19982746238450186 and parameters: {'lambda_l1': 2.4576656352813917e-08, 'lambda_l2': 1.0860641162466502e-06}. Best is trial 46 with value: 0.19954896396241215.\u001b[0m\n",
      "regularization_factors, val_score: 0.199549:  45%|####5     | 9/20 [01:19<01:29,  8.18s/it]\u001b[32m[I 2021-05-19 12:21:01,767]\u001b[0m Trial 51 finished with value: 0.19977710297806162 and parameters: {'lambda_l1': 0.009221347206929626, 'lambda_l2': 0.000226006890354872}. Best is trial 46 with value: 0.19954896396241215.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.199549:  50%|#####     | 10/20 [01:27<01:21,  8.11s/it]\u001b[32m[I 2021-05-19 12:21:09,727]\u001b[0m Trial 52 finished with value: 0.19981870204809635 and parameters: {'lambda_l1': 0.5095770895495357, 'lambda_l2': 0.0001945784917522733}. Best is trial 46 with value: 0.19954896396241215.\u001b[0m\n",
      "regularization_factors, val_score: 0.199495:  55%|#####5    | 11/20 [01:38<01:19,  8.88s/it]\u001b[32m[I 2021-05-19 12:21:20,389]\u001b[0m Trial 53 finished with value: 0.1994949362686813 and parameters: {'lambda_l1': 6.226290649049269e-06, 'lambda_l2': 7.546576624429486}. Best is trial 53 with value: 0.1994949362686813.\u001b[0m\n",
      "regularization_factors, val_score: 0.199475:  60%|######    | 12/20 [01:51<01:21, 10.23s/it]\u001b[32m[I 2021-05-19 12:21:33,693]\u001b[0m Trial 54 finished with value: 0.19947512232352108 and parameters: {'lambda_l1': 6.1098263241512e-07, 'lambda_l2': 8.00842886560023}. Best is trial 54 with value: 0.19947512232352108.\u001b[0m\n",
      "regularization_factors, val_score: 0.199475:  65%|######5   | 13/20 [01:59<01:05,  9.41s/it]\u001b[32m[I 2021-05-19 12:21:41,204]\u001b[0m Trial 55 finished with value: 0.19983890622805187 and parameters: {'lambda_l1': 1.5931959070427541e-06, 'lambda_l2': 0.11601119698605195}. Best is trial 54 with value: 0.19947512232352108.\u001b[0m\n",
      "regularization_factors, val_score: 0.199475:  70%|#######   | 14/20 [02:08<00:55,  9.30s/it]\u001b[32m[I 2021-05-19 12:21:50,266]\u001b[0m Trial 56 finished with value: 0.1998274640933925 and parameters: {'lambda_l1': 7.054272582002147e-06, 'lambda_l2': 2.19899511929434e-08}. Best is trial 54 with value: 0.19947512232352108.\u001b[0m\n",
      "regularization_factors, val_score: 0.199475:  75%|#######5  | 15/20 [02:16<00:45,  9.01s/it]\u001b[32m[I 2021-05-19 12:21:58,578]\u001b[0m Trial 57 finished with value: 0.1997430843129595 and parameters: {'lambda_l1': 2.754727529871313e-06, 'lambda_l2': 0.21047263890916684}. Best is trial 54 with value: 0.19947512232352108.\u001b[0m\n",
      "regularization_factors, val_score: 0.199475:  80%|########  | 16/20 [02:25<00:35,  8.86s/it]\u001b[32m[I 2021-05-19 12:22:07,093]\u001b[0m Trial 58 finished with value: 0.20005455397047403 and parameters: {'lambda_l1': 3.131784476293213e-05, 'lambda_l2': 0.2639978747352157}. Best is trial 54 with value: 0.19947512232352108.\u001b[0m\n",
      "regularization_factors, val_score: 0.199475:  85%|########5 | 17/20 [02:39<00:31, 10.45s/it]\u001b[32m[I 2021-05-19 12:22:21,262]\u001b[0m Trial 59 finished with value: 0.1995517766818038 and parameters: {'lambda_l1': 2.384205054869831e-07, 'lambda_l2': 6.882406187721819}. Best is trial 54 with value: 0.19947512232352108.\u001b[0m\n",
      "regularization_factors, val_score: 0.199475:  90%|######### | 18/20 [02:49<00:20, 10.36s/it]\u001b[32m[I 2021-05-19 12:22:31,391]\u001b[0m Trial 60 finished with value: 0.19989727765882917 and parameters: {'lambda_l1': 7.116595173099512e-05, 'lambda_l2': 0.012942192216122863}. Best is trial 54 with value: 0.19947512232352108.\u001b[0m\n",
      "regularization_factors, val_score: 0.199475:  95%|#########5| 19/20 [02:57<00:09,  9.62s/it]\u001b[32m[I 2021-05-19 12:22:39,293]\u001b[0m Trial 61 finished with value: 0.1997556373337055 and parameters: {'lambda_l1': 3.2376540945296883e-07, 'lambda_l2': 0.8504528215376362}. Best is trial 54 with value: 0.19947512232352108.\u001b[0m\n",
      "regularization_factors, val_score: 0.199475: 100%|##########| 20/20 [03:03<00:00,  8.76s/it]\u001b[32m[I 2021-05-19 12:22:46,054]\u001b[0m Trial 62 finished with value: 0.19984544172357235 and parameters: {'lambda_l1': 8.113356966750258e-05, 'lambda_l2': 0.03654264836542083}. Best is trial 54 with value: 0.19947512232352108.\u001b[0m\n",
      "regularization_factors, val_score: 0.199475: 100%|##########| 20/20 [03:03<00:00,  9.20s/it]\n",
      "min_data_in_leaf, val_score: 0.199473:  20%|##        | 1/5 [00:08<00:33,  8.34s/it]\u001b[32m[I 2021-05-19 12:22:54,412]\u001b[0m Trial 63 finished with value: 0.19947318012048076 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.19947318012048076.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.199464:  40%|####      | 2/5 [00:15<00:23,  7.89s/it]\u001b[32m[I 2021-05-19 12:23:01,986]\u001b[0m Trial 64 finished with value: 0.19946449610190373 and parameters: {'min_child_samples': 10}. Best is trial 64 with value: 0.19946449610190373.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.199391:  60%|######    | 3/5 [00:23<00:15,  7.68s/it]\u001b[32m[I 2021-05-19 12:23:09,423]\u001b[0m Trial 65 finished with value: 0.19939126211724037 and parameters: {'min_child_samples': 25}. Best is trial 65 with value: 0.19939126211724037.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.199391:  80%|########  | 4/5 [00:30<00:07,  7.66s/it]\u001b[32m[I 2021-05-19 12:23:17,035]\u001b[0m Trial 66 finished with value: 0.19948557920613316 and parameters: {'min_child_samples': 50}. Best is trial 65 with value: 0.19939126211724037.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.199391: 100%|##########| 5/5 [00:38<00:00,  7.52s/it]\u001b[32m[I 2021-05-19 12:23:24,321]\u001b[0m Trial 67 finished with value: 0.1994608074470213 and parameters: {'min_child_samples': 100}. Best is trial 65 with value: 0.19939126211724037.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.199391: 100%|##########| 5/5 [00:38<00:00,  7.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.19939126211724037\n",
      "Best params: {'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'feature_pre_filter': False, 'lambda_l1': 6.1098263241512e-07, 'lambda_l2': 8.00842886560023, 'num_leaves': 31, 'feature_fraction': 0.7, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'min_child_samples': 25}\n",
      "  Params: \n",
      "    objective: binary\n",
      "    metric: binary_logloss\n",
      "    verbosity: -1\n",
      "    boosting_type: gbdt\n",
      "    feature_pre_filter: False\n",
      "    lambda_l1: 6.1098263241512e-07\n",
      "    lambda_l2: 8.00842886560023\n",
      "    num_leaves: 31\n",
      "    feature_fraction: 0.7\n",
      "    bagging_fraction: 1.0\n",
      "    bagging_freq: 0\n",
      "    min_child_samples: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import optuna.integration.lightgbm as lgb\n",
    "\n",
    "\n",
    "dtrain = lgb.Dataset(X_25, label=y)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"verbosity\": -1,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "}\n",
    "\n",
    "tuner = lgb.LightGBMTunerCV(\n",
    "    params, dtrain, verbose_eval=0, early_stopping_rounds=100, folds=KFold(n_splits=3), show_progress_bar=True\n",
    ")\n",
    "\n",
    "tuner.run()\n",
    "\n",
    "print(\"Best score:\", tuner.best_score)\n",
    "best_params = tuner.best_params\n",
    "print(\"Best params:\", best_params)\n",
    "print(\"  Params: \")\n",
    "for key, value in best_params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.945 (0.002)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = lgb.Dataset(X_25, label=y)\n",
    "params = best_params\n",
    "\n",
    "\n",
    "# evaluate the model\n",
    "\n",
    "model = LGBMClassifier()\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AML",
   "language": "python",
   "name": "aml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
