{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the small project data into Python\n",
    "\n",
    "This file will show how to read the data from the files `train.h5` and `test.h5` into Python, for training.\n",
    "The files are available at:\n",
    "\n",
    "<https://www.nbi.dk/~petersen/Teaching/ML2020/SmallProject/train.h5>\n",
    "\n",
    "<https://www.nbi.dk/~petersen/Teaching/ML2020/SmallProject/test.h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by opening the files and loading them into a Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(name):\n",
    "    with h5py.File(f'{name}.h5', 'r') as f:\n",
    "        return pandas.DataFrame(f[name][:])\n",
    "\n",
    "train = load_data('train')\n",
    "test  = load_data('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can verify the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data set: (162500, 166)\n",
      "Shape of test data set: (160651, 164)\n"
     ]
    }
   ],
   "source": [
    "print (f'Shape of training data set: {train.shape}')\n",
    "print (f'Shape of test data set: {test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the test set contains 2 columns less: `Truth` and `p_truth_E`.\n",
    "    \n",
    "Then we copy the variable list from the course website <https://www.nbi.dk/~petersen/Teaching/ML2020/SmallProject/VariableList.html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_variables = ['actualInteractionsPerCrossing', 'averageInteractionsPerCrossing', 'correctedActualMu', 'correctedAverageMu', 'correctedScaledActualMu', 'correctedScaledAverageMu', 'NvtxReco', 'p_nTracks', 'p_pt_track', 'p_eta', 'p_phi', 'p_charge', 'p_qOverP', 'p_z0', 'p_d0', 'p_sigmad0', 'p_d0Sig', 'p_EptRatio', 'p_dPOverP', 'p_z0theta', 'p_etaCluster', 'p_phiCluster', 'p_eCluster', 'p_rawEtaCluster', 'p_rawPhiCluster', 'p_rawECluster', 'p_eClusterLr0', 'p_eClusterLr1', 'p_eClusterLr2', 'p_eClusterLr3', 'p_etaClusterLr1', 'p_etaClusterLr2', 'p_phiClusterLr2', 'p_eAccCluster', 'p_f0Cluster', 'p_etaCalo', 'p_phiCalo', 'p_eTileGap3Cluster', 'p_cellIndexCluster', 'p_phiModCalo', 'p_etaModCalo', 'p_dPhiTH3', 'p_R12', 'p_fTG3', 'p_weta2', 'p_Reta', 'p_Rphi', 'p_Eratio', 'p_f1', 'p_f3', 'p_Rhad', 'p_Rhad1', 'p_deltaEta1', 'p_deltaPhiRescaled2', 'p_TRTPID', 'p_TRTTrackOccupancy', 'p_numberOfInnermostPixelHits', 'p_numberOfPixelHits', 'p_numberOfSCTHits', 'p_numberOfTRTHits', 'p_numberOfTRTXenonHits', 'p_chi2', 'p_ndof', 'p_SharedMuonTrack', 'p_E7x7_Lr2', 'p_E7x7_Lr3', 'p_E_Lr0_HiG', 'p_E_Lr0_LowG', 'p_E_Lr0_MedG', 'p_E_Lr1_HiG', 'p_E_Lr1_LowG', 'p_E_Lr1_MedG', 'p_E_Lr2_HiG', 'p_E_Lr2_LowG', 'p_E_Lr2_MedG', 'p_E_Lr3_HiG', 'p_E_Lr3_LowG', 'p_E_Lr3_MedG', 'p_ambiguityType', 'p_asy1', 'p_author', 'p_barys1', 'p_core57cellsEnergyCorrection', 'p_deltaEta0', 'p_deltaEta2', 'p_deltaEta3', 'p_deltaPhi0', 'p_deltaPhi1', 'p_deltaPhi2', 'p_deltaPhi3', 'p_deltaPhiFromLastMeasurement', 'p_deltaPhiRescaled0', 'p_deltaPhiRescaled1', 'p_deltaPhiRescaled3', 'p_e1152', 'p_e132', 'p_e235', 'p_e255', 'p_e2ts1', 'p_ecore', 'p_emins1', 'p_etconeCorrBitset', 'p_ethad', 'p_ethad1', 'p_f1core', 'p_f3core', 'p_maxEcell_energy', 'p_maxEcell_gain', 'p_maxEcell_time', 'p_maxEcell_x', 'p_maxEcell_y', 'p_maxEcell_z', 'p_nCells_Lr0_HiG', 'p_nCells_Lr0_LowG', 'p_nCells_Lr0_MedG', 'p_nCells_Lr1_HiG', 'p_nCells_Lr1_LowG', 'p_nCells_Lr1_MedG', 'p_nCells_Lr2_HiG', 'p_nCells_Lr2_LowG', 'p_nCells_Lr2_MedG', 'p_nCells_Lr3_HiG', 'p_nCells_Lr3_LowG', 'p_nCells_Lr3_MedG', 'p_pos', 'p_pos7', 'p_poscs1', 'p_poscs2', 'p_ptconeCorrBitset', 'p_ptconecoreTrackPtrCorrection', 'p_r33over37allcalo', 'p_topoetconeCorrBitset', 'p_topoetconecoreConeEnergyCorrection', 'p_topoetconecoreConeSCEnergyCorrection', 'p_weta1', 'p_widths1', 'p_widths2', 'p_wtots1', 'p_e233', 'p_e237', 'p_e277', 'p_e2tsts1', 'p_ehad1', 'p_emaxs1', 'p_fracs1', 'p_DeltaE', 'p_E3x5_Lr0', 'p_E3x5_Lr1', 'p_E3x5_Lr2', 'p_E3x5_Lr3', 'p_E5x7_Lr0', 'p_E5x7_Lr1', 'p_E5x7_Lr2', 'p_E5x7_Lr3', 'p_E7x11_Lr0', 'p_E7x11_Lr1', 'p_E7x11_Lr2', 'p_E7x11_Lr3', 'p_E7x7_Lr0', 'p_E7x7_Lr1' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we divide the training data into data (`X`) and labels (`y`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (162500, 160)\n",
      "Shape of y: (162500,)\n"
     ]
    }
   ],
   "source": [
    "X = train[all_variables]\n",
    "y = train['Truth']\n",
    "\n",
    "print (f'Shape of X: {X.shape}')\n",
    "print (f'Shape of y: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualInteractionsPerCrossing</th>\n",
       "      <th>averageInteractionsPerCrossing</th>\n",
       "      <th>correctedActualMu</th>\n",
       "      <th>correctedAverageMu</th>\n",
       "      <th>correctedScaledActualMu</th>\n",
       "      <th>correctedScaledAverageMu</th>\n",
       "      <th>NvtxReco</th>\n",
       "      <th>p_nTracks</th>\n",
       "      <th>p_pt_track</th>\n",
       "      <th>p_eta</th>\n",
       "      <th>...</th>\n",
       "      <th>p_E5x7_Lr0</th>\n",
       "      <th>p_E5x7_Lr1</th>\n",
       "      <th>p_E5x7_Lr2</th>\n",
       "      <th>p_E5x7_Lr3</th>\n",
       "      <th>p_E7x11_Lr0</th>\n",
       "      <th>p_E7x11_Lr1</th>\n",
       "      <th>p_E7x11_Lr2</th>\n",
       "      <th>p_E7x11_Lr3</th>\n",
       "      <th>p_E7x7_Lr0</th>\n",
       "      <th>p_E7x7_Lr1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>42011.792969</td>\n",
       "      <td>1.834715</td>\n",
       "      <td>...</td>\n",
       "      <td>215.588013</td>\n",
       "      <td>43402.332031</td>\n",
       "      <td>74045.820312</td>\n",
       "      <td>337.980713</td>\n",
       "      <td>273.708801</td>\n",
       "      <td>43091.683594</td>\n",
       "      <td>74447.539062</td>\n",
       "      <td>470.177124</td>\n",
       "      <td>273.708801</td>\n",
       "      <td>43091.683594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   actualInteractionsPerCrossing  averageInteractionsPerCrossing  \\\n",
       "0                           26.5                            26.5   \n",
       "\n",
       "   correctedActualMu  correctedAverageMu  correctedScaledActualMu  \\\n",
       "0               26.5                26.5                     26.5   \n",
       "\n",
       "   correctedScaledAverageMu  NvtxReco  p_nTracks    p_pt_track     p_eta  ...  \\\n",
       "0                      26.5        18          3  42011.792969  1.834715  ...   \n",
       "\n",
       "   p_E5x7_Lr0    p_E5x7_Lr1    p_E5x7_Lr2  p_E5x7_Lr3  p_E7x11_Lr0  \\\n",
       "0  215.588013  43402.332031  74045.820312  337.980713   273.708801   \n",
       "\n",
       "    p_E7x11_Lr1   p_E7x11_Lr2  p_E7x11_Lr3  p_E7x7_Lr0    p_E7x7_Lr1  \n",
       "0  43091.683594  74447.539062   470.177124  273.708801  43091.683594  \n",
       "\n",
       "[1 rows x 160 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_count = y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion: 2.96 : 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Proportion:', round(target_count[1] / target_count[0], 2), ': 1')\n",
    "\n",
    "target_count.plot(kind='bar', title='Count (target)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eventNumber                       0\n",
       "runNumber                         0\n",
       "actualInteractionsPerCrossing     0\n",
       "averageInteractionsPerCrossing    0\n",
       "correctedActualMu                 0\n",
       "                                 ..\n",
       "p_E7x11_Lr2                       0\n",
       "p_E7x11_Lr3                       0\n",
       "p_E7x7_Lr0                        0\n",
       "p_E7x7_Lr1                        0\n",
       "index                             0\n",
       "Length: 166, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No nulls\n",
    "### Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_X = deepcopy(X) \n",
    "# This loop transforms every variable _independently_ \n",
    "for variable in X.columns:     \n",
    "    transformed_X[variable] = RobustScaler().fit_transform(np.array(transformed_X[variable]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select k Best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niallgray/opt/miniconda3/envs/aml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [ 67  73  76 101 113 119 122 128 131 136] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
      "/Users/niallgray/opt/miniconda3/envs/aml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['correctedScaledAverageMu', 'p_eClusterLr0', 'p_dPhiTH3', 'p_R12',\n",
       "       'p_fTG3', 'p_weta2', 'p_Rphi', 'p_Eratio', 'p_f1', 'p_ndof',\n",
       "       'p_E_Lr1_LowG', 'p_E_Lr3_HiG', 'p_deltaPhiRescaled3', 'p_e132',\n",
       "       'p_e255', 'p_e2ts1', 'p_emins1', 'p_pos7', 'p_widths2', 'p_wtots1',\n",
       "       'p_e237', 'p_e277', 'p_fracs1', 'p_E3x5_Lr2', 'p_E5x7_Lr2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and fit selector\n",
    "selector = SelectKBest(score_func=f_classif, k=25)\n",
    "X_25 = selector.fit_transform(transformed_X, y)\n",
    "# Get columns to keep and create new dataframe with those only\n",
    "cols = selector.get_support(indices=True)\n",
    "features_df_new = train.iloc[:,cols]\n",
    "features_df_new.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian optimisation of hyperparameters and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GBC_CrossValidation(n_estimators, learning_rate, max_depth, data, targets):\n",
    "    \"\"\"Decision Tree cross validation.\n",
    "       Fits a Decision Tree with the given paramaters to the target \n",
    "       given data, calculated a CV accuracy score and returns the mean.\n",
    "       The goal is to find combinations\n",
    "       that maximize the accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    estimator = GradientBoostingClassifier(n_estimators=n_estimators, learning_rate=learning_rate, \n",
    "                                 max_depth=max_depth, random_state=0)\n",
    "    \n",
    "    cval = cross_val_score(estimator, data, targets, scoring='accuracy', cv=5)\n",
    "    \n",
    "    return cval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_GBC(data, targets, pars, n_iter=5):\n",
    "    \"\"\"Apply Bayesian Optimization to Decision Tree parameters.\"\"\"\n",
    "    \n",
    "    def crossval_wrapper(n_estimators, learning_rate, max_depth):\n",
    "        \"\"\"Wrapper of Decision Tree cross validation. \n",
    "           max_depth and n_estimators\n",
    "           are cast to integer before we pass them along.\n",
    "        \"\"\"\n",
    "        return GBC_CrossValidation(n_estimators=int(n_estimators), \n",
    "                                            learning_rate=learning_rate, \n",
    "                                            max_depth=int(max_depth),\n",
    "                                            data=data, \n",
    "                                            targets=targets)\n",
    "\n",
    "    optimizer = BayesianOptimization(f=crossval_wrapper, \n",
    "                                     pbounds=pars, \n",
    "                                     random_state=42, \n",
    "                                     verbose=100)\n",
    "    optimizer.maximize(init_points=4, n_iter=n_iter)\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learni... | max_depth | n_esti... |\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0.37460266483547777, 4.802857225639665, 379.3972738151323)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-a341a82c2565>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                   }\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m BayesianOptimization = optimize_GBC(X_25, \n\u001b[0m\u001b[1;32m      7\u001b[0m                                              \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                              \u001b[0mparameters_BayesianOptimization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-0d416a5e2a34>\u001b[0m in \u001b[0;36moptimize_GBC\u001b[0;34m(data, targets, pars, n_iter)\u001b[0m\n\u001b[1;32m     17\u001b[0m                                      \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                      verbose=100)\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZATION_END\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-0d416a5e2a34>\u001b[0m in \u001b[0;36mcrossval_wrapper\u001b[0;34m(n_estimators, learning_rate, max_depth)\u001b[0m\n\u001b[1;32m      7\u001b[0m            \u001b[0mare\u001b[0m \u001b[0mcast\u001b[0m \u001b[0mto\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mbefore\u001b[0m \u001b[0mwe\u001b[0m \u001b[0;32mpass\u001b[0m \u001b[0mthem\u001b[0m \u001b[0malong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \"\"\"\n\u001b[0;32m----> 9\u001b[0;31m         return GBC_CrossValidation(n_estimators=int(n_estimators), \n\u001b[0m\u001b[1;32m     10\u001b[0m                                             \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                             \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-375f0d47a8fe>\u001b[0m in \u001b[0;36mGBC_CrossValidation\u001b[0;34m(n_estimators, learning_rate, max_depth, data, targets)\u001b[0m\n\u001b[1;32m     10\u001b[0m                                  max_depth=max_depth, random_state=0)\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mcval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[1;32m    441\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    244\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[1;32m    245\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[0;32m--> 246\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    247\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    248\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         n_stages = self._fit_stages(\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             sample_weight_val, begin_at_stage, monitor)\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0;31m# fit next stage of trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[1;32m    562\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                 random_state, X_csc, X_csr)\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0m\u001b[1;32m    215\u001b[0m                      check_input=False)\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \"\"\"\n\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1248\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    387\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parameters_BayesianOptimization = {\"learning_rate\": (0.0001, 1), \n",
    "                                   \"max_depth\": (1, 5),\n",
    "                                   \"n_estimators\": (50,500)\n",
    "                                  }\n",
    "\n",
    "BayesianOptimization = optimize_GBC(X_25, \n",
    "                                             y, \n",
    "                                             parameters_BayesianOptimization, \n",
    "                                             n_iter=5)\n",
    "print(BayesianOptimization.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation on result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators=int(BayesianOptimization.max['params']['n_estimators']), \n",
    "                                 learning_rate=BayesianOptimization.max['params']['learning_rate'], \n",
    "                                 max_depth=BayesianOptimization.max['params']['max_depth'], \n",
    "                                 random_state=0)\n",
    "scores = cross_val_score(gbc, X_25, y, cv=5, scoring='f1') \n",
    "print(f\"{scores.mean():.4f} accuracy with a standard deviation of {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.945 (0.002)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "data_train = lgb.Dataset(X_25, label=y)\n",
    "params = {'objective': 'binary',\n",
    "          'boosting_type': 'gbdt',\n",
    "          'metric': 'binary_logloss',\n",
    "          'learning_rate': 0.01,\n",
    "          'num_leaves': 10,\n",
    "          'max_depth': 10,\n",
    "          'min_data': 10,\n",
    "          'verbose': 0,\n",
    "          'force_col_wise': True}\n",
    "\n",
    "#lgb_clf = lgb.train(params, train_set=data_train, num_boost_round=300)\n",
    "#lgb.cv(params, data_train, num_boost_round=300, nfold=5)\n",
    "\n",
    "\n",
    "# y_pred = np.around(lgb_clf.predict(test_X))\n",
    "# acc = accuracy_score(y_pred, test_y)\n",
    "# print(f\"Train accuracy: {acc*100.0:.2f}%\")\n",
    "\n",
    "# evaluate the model\n",
    "\n",
    "model = LGBMClassifier()\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-22 18:47:47,100]\u001b[0m A new study created in memory with name: no-name-4657967a-ea39-4222-9bcc-232a22b4cd09\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "from optuna.pruners import MedianPruner\n",
    "import lightgbm as lgb\n",
    "\n",
    "#%%\n",
    "\n",
    "lgb_data_train = lgb.Dataset(X_25, label=y)\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    boosting_types = [\"gbdt\", \"rf\", \"dart\"]\n",
    "    boosting_type = trial.suggest_categorical(\"boosting_type\", boosting_types)\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"boosting\": boosting_type,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 63),\n",
    "        \"min_child_weight\": trial.suggest_loguniform(\"min_child_weight\", 1e-5, 10),\n",
    "        \"scale_pos_weight\": trial.suggest_uniform(\"scale_pos_weight\", 10.0, 30.0),\n",
    "    }\n",
    "\n",
    "    N_iterations_max = 10_000\n",
    "    early_stopping_rounds = 50\n",
    "\n",
    "    if boosting_type == \"dart\":\n",
    "        N_iterations_max = 100\n",
    "        early_stopping_rounds = None\n",
    "\n",
    "    cv_res = lgb.cv(\n",
    "        params,\n",
    "        lgb_data_train,\n",
    "        num_boost_round=N_iterations_max,\n",
    "        early_stopping_rounds=early_stopping_rounds,\n",
    "        verbose_eval=False,\n",
    "        seed=42,\n",
    "        callbacks=[LightGBMPruningCallback(trial, \"auc\")],\n",
    "    )\n",
    "\n",
    "    num_boost_round = len(cv_res[\"auc-mean\"])\n",
    "    trial.set_user_attr(\"num_boost_round\", num_boost_round)\n",
    "    return cv_res[\"auc-mean\"][-1]\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=TPESampler(seed=42),\n",
    "    pruner=MedianPruner(n_warmup_steps=50),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niallgray/opt/miniconda3/envs/aml/lib/python3.8/site-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78b8dad648ca437ea3303d599cb02cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                                                           \n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.200055:  14%|#4        | 1/7 [78:35:32<00:50,  8.44s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 97196, number of negative: 32804\n",
      "\u001b[33m[W 2021-05-22 18:49:02,999]\u001b[0m Trial 0 failed because of the following error: LightGBMError('Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /tmp/pip-req-build-12fs9jsp/compile/src/boosting/rf.hpp, line 35 .\\n')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/niallgray/opt/miniconda3/envs/aml/lib/python3.8/site-packages/optuna/_optimize.py\", line 217, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"<ipython-input-36-205b099d44e5>\", line 35, in objective\n",
      "    cv_res = lgb.cv(\n",
      "  File \"/Users/niallgray/opt/miniconda3/envs/aml/lib/python3.8/site-packages/lightgbm/engine.py\", line 557, in cv\n",
      "    cvfolds = _make_n_folds(train_set, folds=folds, nfold=nfold,\n",
      "  File \"/Users/niallgray/opt/miniconda3/envs/aml/lib/python3.8/site-packages/lightgbm/engine.py\", line 367, in _make_n_folds\n",
      "    cvbooster = Booster(tparam, train_set)\n",
      "  File \"/Users/niallgray/opt/miniconda3/envs/aml/lib/python3.8/site-packages/lightgbm/basic.py\", line 2234, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/niallgray/opt/miniconda3/envs/aml/lib/python3.8/site-packages/lightgbm/basic.py\", line 110, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /tmp/pip-req-build-12fs9jsp/compile/src/boosting/rf.hpp, line 35 .\n",
      "\u001b[0m\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /tmp/pip-req-build-12fs9jsp/compile/src/boosting/rf.hpp, line 35 .\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-b2f2701dc7e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    398\u001b[0m             )\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAIL\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-205b099d44e5>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mearly_stopping_rounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     cv_res = lgb.cv(\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mlgb_data_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, fpreproc, verbose_eval, show_stdv, seed, callbacks, eval_train_metric, return_cvbooster)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m     cvfolds = _make_n_folds(train_set, folds=folds, nfold=nfold,\n\u001b[0m\u001b[1;32m    558\u001b[0m                             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpreproc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfpreproc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m                             \u001b[0mstratified\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratified\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36m_make_n_folds\u001b[0;34m(full_data, folds, nfold, params, seed, fpreproc, stratified, shuffle, eval_train_metric)\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mtparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mcvbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0meval_train_metric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0mcvbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[1;32m   2232\u001b[0m             \u001b[0mparams_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_dict_to_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2233\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2234\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterCreate(\n\u001b[0m\u001b[1;32m   2235\u001b[0m                 \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2236\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/aml/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \"\"\"\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLightGBMError\u001b[0m: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /tmp/pip-req-build-12fs9jsp/compile/src/boosting/rf.hpp, line 35 .\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=100, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-22 18:49:19,275]\u001b[0m A new study created in memory with name: no-name-799168dd-8c77-478b-8cf5-5acc0a19dbe5\u001b[0m\n",
      "feature_fraction, val_score: 0.200063:  14%|#4        | 1/7 [00:06<00:36,  6.03s/it]\u001b[32m[I 2021-05-22 18:49:25,317]\u001b[0m Trial 0 finished with value: 0.20006250926043956 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.20006250926043956.\u001b[0m\n",
      "feature_fraction, val_score: 0.199997:  29%|##8       | 2/7 [00:11<00:27,  5.49s/it]\u001b[32m[I 2021-05-22 18:49:30,436]\u001b[0m Trial 1 finished with value: 0.19999731670795493 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 0.19999731670795493.\u001b[0m\n",
      "feature_fraction, val_score: 0.199997:  43%|####2     | 3/7 [00:17<00:22,  5.69s/it]\u001b[32m[I 2021-05-22 18:49:36,371]\u001b[0m Trial 2 finished with value: 0.2001174272598327 and parameters: {'feature_fraction': 0.7}. Best is trial 1 with value: 0.19999731670795493.\u001b[0m\n",
      "feature_fraction, val_score: 0.199997:  57%|#####7    | 4/7 [00:23<00:18,  6.06s/it]\u001b[32m[I 2021-05-22 18:49:43,002]\u001b[0m Trial 3 finished with value: 0.2000839795112815 and parameters: {'feature_fraction': 0.4}. Best is trial 1 with value: 0.19999731670795493.\u001b[0m\n",
      "feature_fraction, val_score: 0.199997:  71%|#######1  | 5/7 [00:29<00:11,  5.96s/it]\u001b[32m[I 2021-05-22 18:49:48,766]\u001b[0m Trial 4 finished with value: 0.20025142913671434 and parameters: {'feature_fraction': 1.0}. Best is trial 1 with value: 0.19999731670795493.\u001b[0m\n",
      "feature_fraction, val_score: 0.199997:  86%|########5 | 6/7 [00:36<00:06,  6.19s/it]\u001b[32m[I 2021-05-22 18:49:55,405]\u001b[0m Trial 5 finished with value: 0.20012820236754705 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 0.19999731670795493.\u001b[0m\n",
      "feature_fraction, val_score: 0.199986: 100%|##########| 7/7 [00:40<00:00,  5.75s/it]\u001b[32m[I 2021-05-22 18:50:00,258]\u001b[0m Trial 6 finished with value: 0.19998576332587892 and parameters: {'feature_fraction': 0.5}. Best is trial 6 with value: 0.19998576332587892.\u001b[0m\n",
      "feature_fraction, val_score: 0.199986: 100%|##########| 7/7 [00:40<00:00,  5.85s/it]\n",
      "num_leaves, val_score: 0.199986:   5%|5         | 1/20 [00:06<01:54,  6.00s/it]\u001b[32m[I 2021-05-22 18:50:06,268]\u001b[0m Trial 7 finished with value: 0.200876918970715 and parameters: {'num_leaves': 74}. Best is trial 7 with value: 0.200876918970715.\u001b[0m\n",
      "num_leaves, val_score: 0.199986:  10%|#         | 2/20 [00:14<02:13,  7.44s/it]\u001b[32m[I 2021-05-22 18:50:14,719]\u001b[0m Trial 8 finished with value: 0.2026688939659699 and parameters: {'num_leaves': 216}. Best is trial 7 with value: 0.200876918970715.\u001b[0m\n",
      "num_leaves, val_score: 0.199986:  15%|#5        | 3/20 [00:23<02:18,  8.13s/it]\u001b[32m[I 2021-05-22 18:50:23,666]\u001b[0m Trial 9 finished with value: 0.2025282391570357 and parameters: {'num_leaves': 214}. Best is trial 7 with value: 0.200876918970715.\u001b[0m\n",
      "num_leaves, val_score: 0.199986:  20%|##        | 4/20 [00:31<02:08,  8.04s/it]\u001b[32m[I 2021-05-22 18:50:31,574]\u001b[0m Trial 10 finished with value: 0.2024213668713891 and parameters: {'num_leaves': 182}. Best is trial 7 with value: 0.200876918970715.\u001b[0m\n",
      "num_leaves, val_score: 0.199986:  25%|##5       | 5/20 [00:39<02:03,  8.23s/it]\u001b[32m[I 2021-05-22 18:50:40,144]\u001b[0m Trial 11 finished with value: 0.20254823291888382 and parameters: {'num_leaves': 171}. Best is trial 7 with value: 0.200876918970715.\u001b[0m\n",
      "num_leaves, val_score: 0.199986:  30%|###       | 6/20 [00:45<01:43,  7.42s/it]\u001b[32m[I 2021-05-22 18:50:45,976]\u001b[0m Trial 12 finished with value: 0.2008341402586711 and parameters: {'num_leaves': 86}. Best is trial 12 with value: 0.2008341402586711.\u001b[0m\n",
      "num_leaves, val_score: 0.199986:  35%|###5      | 7/20 [00:52<01:34,  7.27s/it]\u001b[32m[I 2021-05-22 18:50:52,934]\u001b[0m Trial 13 finished with value: 0.20154202168168148 and parameters: {'num_leaves': 144}. Best is trial 12 with value: 0.2008341402586711.\u001b[0m\n",
      "num_leaves, val_score: 0.199986:  40%|####      | 8/20 [01:01<01:32,  7.69s/it]\u001b[32m[I 2021-05-22 18:51:01,527]\u001b[0m Trial 14 finished with value: 0.20266348093834075 and parameters: {'num_leaves': 225}. Best is trial 12 with value: 0.2008341402586711.\u001b[0m\n",
      "num_leaves, val_score: 0.199986:  45%|####5     | 9/20 [01:07<01:17,  7.08s/it]\u001b[32m[I 2021-05-22 18:51:07,279]\u001b[0m Trial 15 finished with value: 0.20098793867897236 and parameters: {'num_leaves': 90}. Best is trial 12 with value: 0.2008341402586711.\u001b[0m\n",
      "num_leaves, val_score: 0.199986:  50%|#####     | 10/20 [01:15<01:15,  7.54s/it]\u001b[32m[I 2021-05-22 18:51:15,844]\u001b[0m Trial 16 finished with value: 0.20303447410867115 and parameters: {'num_leaves': 230}. Best is trial 12 with value: 0.2008341402586711.\u001b[0m\n",
      "num_leaves, val_score: 0.199986:  55%|#####5    | 11/20 [01:26<01:17,  8.62s/it]\u001b[32m[I 2021-05-22 18:51:26,913]\u001b[0m Trial 17 finished with value: 0.20141194921688096 and parameters: {'num_leaves': 3}. Best is trial 12 with value: 0.2008341402586711.\u001b[0m\n",
      "num_leaves, val_score: 0.199986:  60%|######    | 12/20 [01:32<01:01,  7.74s/it]\u001b[32m[I 2021-05-22 18:51:32,631]\u001b[0m Trial 18 finished with value: 0.20073079805722419 and parameters: {'num_leaves': 70}. Best is trial 18 with value: 0.20073079805722419.\u001b[0m\n",
      "num_leaves, val_score: 0.199986:  65%|######5   | 13/20 [01:37<00:47,  6.83s/it]\u001b[32m[I 2021-05-22 18:51:37,368]\u001b[0m Trial 19 finished with value: 0.19998576332587892 and parameters: {'num_leaves': 31}. Best is trial 19 with value: 0.19998576332587892.\u001b[0m\n",
      "num_leaves, val_score: 0.199986:  70%|#######   | 14/20 [01:46<00:45,  7.56s/it]\u001b[32m[I 2021-05-22 18:51:46,612]\u001b[0m Trial 20 finished with value: 0.2002095547229754 and parameters: {'num_leaves': 6}. Best is trial 19 with value: 0.19998576332587892.\u001b[0m\n",
      "num_leaves, val_score: 0.199986:  75%|#######5  | 15/20 [01:50<00:33,  6.66s/it]\u001b[32m[I 2021-05-22 18:51:51,211]\u001b[0m Trial 21 finished with value: 0.20119964326530315 and parameters: {'num_leaves': 7}. Best is trial 19 with value: 0.19998576332587892.\u001b[0m\n",
      "num_leaves, val_score: 0.199986:  80%|########  | 16/20 [01:55<00:24,  6.08s/it]\u001b[32m[I 2021-05-22 18:51:55,932]\u001b[0m Trial 22 finished with value: 0.20006081751697294 and parameters: {'num_leaves': 30}. Best is trial 19 with value: 0.19998576332587892.\u001b[0m\n",
      "num_leaves, val_score: 0.199986:  85%|########5 | 17/20 [02:00<00:16,  5.64s/it]\u001b[32m[I 2021-05-22 18:52:00,537]\u001b[0m Trial 23 finished with value: 0.2001150433801077 and parameters: {'num_leaves': 39}. Best is trial 19 with value: 0.19998576332587892.\u001b[0m\n",
      "num_leaves, val_score: 0.199986:  90%|######### | 18/20 [02:05<00:11,  5.51s/it]\u001b[32m[I 2021-05-22 18:52:05,761]\u001b[0m Trial 24 finished with value: 0.2002563529473538 and parameters: {'num_leaves': 42}. Best is trial 19 with value: 0.19998576332587892.\u001b[0m\n",
      "num_leaves, val_score: 0.199986:  95%|#########5| 19/20 [02:11<00:05,  5.76s/it]\u001b[32m[I 2021-05-22 18:52:12,106]\u001b[0m Trial 25 finished with value: 0.20130909600062977 and parameters: {'num_leaves': 113}. Best is trial 19 with value: 0.19998576332587892.\u001b[0m\n",
      "num_leaves, val_score: 0.199986: 100%|##########| 20/20 [02:17<00:00,  5.63s/it]\u001b[32m[I 2021-05-22 18:52:17,439]\u001b[0m Trial 26 finished with value: 0.20005214896569481 and parameters: {'num_leaves': 41}. Best is trial 19 with value: 0.19998576332587892.\u001b[0m\n",
      "num_leaves, val_score: 0.199986: 100%|##########| 20/20 [02:17<00:00,  6.86s/it]\n",
      "bagging, val_score: 0.199986:  10%|#         | 1/10 [00:05<00:52,  5.78s/it]\u001b[32m[I 2021-05-22 18:52:23,230]\u001b[0m Trial 27 finished with value: 0.20005152644278915 and parameters: {'bagging_fraction': 0.8696124275952481, 'bagging_freq': 1}. Best is trial 27 with value: 0.20005152644278915.\u001b[0m\n",
      "bagging, val_score: 0.199986:  20%|##        | 2/10 [00:11<00:46,  5.85s/it]\u001b[32m[I 2021-05-22 18:52:29,125]\u001b[0m Trial 28 finished with value: 0.20033805457865894 and parameters: {'bagging_fraction': 0.6788503701206317, 'bagging_freq': 6}. Best is trial 27 with value: 0.20005152644278915.\u001b[0m\n",
      "bagging, val_score: 0.199870:  30%|###       | 3/10 [00:18<00:42,  6.11s/it]\u001b[32m[I 2021-05-22 18:52:35,550]\u001b[0m Trial 29 finished with value: 0.19987020697375024 and parameters: {'bagging_fraction': 0.840081722766568, 'bagging_freq': 3}. Best is trial 29 with value: 0.19987020697375024.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.199870:  40%|####      | 4/10 [00:25<00:38,  6.42s/it]\u001b[32m[I 2021-05-22 18:52:42,450]\u001b[0m Trial 30 finished with value: 0.2000806412158076 and parameters: {'bagging_fraction': 0.7831042903007852, 'bagging_freq': 5}. Best is trial 29 with value: 0.19987020697375024.\u001b[0m\n",
      "bagging, val_score: 0.199870:  50%|#####     | 5/10 [00:33<00:35,  7.13s/it]\u001b[32m[I 2021-05-22 18:52:50,828]\u001b[0m Trial 31 finished with value: 0.2002204313377217 and parameters: {'bagging_fraction': 0.6727411846321532, 'bagging_freq': 3}. Best is trial 29 with value: 0.19987020697375024.\u001b[0m\n",
      "bagging, val_score: 0.199870:  60%|######    | 6/10 [00:38<00:26,  6.55s/it]\u001b[32m[I 2021-05-22 18:52:56,244]\u001b[0m Trial 32 finished with value: 0.2009497794388603 and parameters: {'bagging_fraction': 0.5208424470828812, 'bagging_freq': 7}. Best is trial 29 with value: 0.19987020697375024.\u001b[0m\n",
      "bagging, val_score: 0.199870:  70%|#######   | 7/10 [00:44<00:18,  6.21s/it]\u001b[32m[I 2021-05-22 18:53:01,749]\u001b[0m Trial 33 finished with value: 0.2011122965497146 and parameters: {'bagging_fraction': 0.4487416381455262, 'bagging_freq': 4}. Best is trial 29 with value: 0.19987020697375024.\u001b[0m\n",
      "bagging, val_score: 0.199870:  80%|########  | 8/10 [00:49<00:11,  5.98s/it]\u001b[32m[I 2021-05-22 18:53:07,230]\u001b[0m Trial 34 finished with value: 0.2000637825512298 and parameters: {'bagging_fraction': 0.7965204240769268, 'bagging_freq': 1}. Best is trial 29 with value: 0.19987020697375024.\u001b[0m\n",
      "bagging, val_score: 0.199870:  90%|######### | 9/10 [00:55<00:05,  5.80s/it]\u001b[32m[I 2021-05-22 18:53:12,633]\u001b[0m Trial 35 finished with value: 0.20044224027789795 and parameters: {'bagging_fraction': 0.5900230133056779, 'bagging_freq': 5}. Best is trial 29 with value: 0.19987020697375024.\u001b[0m\n",
      "bagging, val_score: 0.199870: 100%|##########| 10/10 [01:01<00:00,  5.82s/it]\u001b[32m[I 2021-05-22 18:53:18,503]\u001b[0m Trial 36 finished with value: 0.20007216979906087 and parameters: {'bagging_fraction': 0.857066925905009, 'bagging_freq': 7}. Best is trial 29 with value: 0.19987020697375024.\u001b[0m\n",
      "bagging, val_score: 0.199870: 100%|##########| 10/10 [01:01<00:00,  6.11s/it]\n",
      "feature_fraction_stage2, val_score: 0.199870:  17%|#6        | 1/6 [00:05<00:29,  5.92s/it]\u001b[32m[I 2021-05-22 18:53:24,430]\u001b[0m Trial 37 finished with value: 0.20019352276427002 and parameters: {'feature_fraction': 0.45199999999999996}. Best is trial 37 with value: 0.20019352276427002.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.199870:  33%|###3      | 2/6 [00:12<00:24,  6.09s/it]\u001b[32m[I 2021-05-22 18:53:30,639]\u001b[0m Trial 38 finished with value: 0.19987020697375024 and parameters: {'feature_fraction': 0.516}. Best is trial 38 with value: 0.19987020697375024.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.199870:  50%|#####     | 3/6 [00:18<00:18,  6.15s/it]\u001b[32m[I 2021-05-22 18:53:36,870]\u001b[0m Trial 39 finished with value: 0.19996091783165013 and parameters: {'feature_fraction': 0.5479999999999999}. Best is trial 38 with value: 0.19987020697375024.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.199870:  67%|######6   | 4/6 [00:24<00:11,  5.98s/it]\u001b[32m[I 2021-05-22 18:53:42,571]\u001b[0m Trial 40 finished with value: 0.20010533881153425 and parameters: {'feature_fraction': 0.484}. Best is trial 38 with value: 0.19987020697375024.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.199870:  83%|########3 | 5/6 [00:30<00:06,  6.04s/it]\u001b[32m[I 2021-05-22 18:53:48,726]\u001b[0m Trial 41 finished with value: 0.20019352276427002 and parameters: {'feature_fraction': 0.42}. Best is trial 38 with value: 0.19987020697375024.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.199870: 100%|##########| 6/6 [00:36<00:00,  6.13s/it]\u001b[32m[I 2021-05-22 18:53:55,034]\u001b[0m Trial 42 finished with value: 0.19996091783165013 and parameters: {'feature_fraction': 0.58}. Best is trial 38 with value: 0.19987020697375024.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.199870: 100%|##########| 6/6 [00:36<00:00,  6.09s/it]\n",
      "regularization_factors, val_score: 0.199574:   5%|5         | 1/20 [00:07<02:28,  7.80s/it]\u001b[32m[I 2021-05-22 18:54:02,840]\u001b[0m Trial 43 finished with value: 0.19957367190652828 and parameters: {'lambda_l1': 3.4253823141860353, 'lambda_l2': 0.35694255292860133}. Best is trial 43 with value: 0.19957367190652828.\u001b[0m\n",
      "regularization_factors, val_score: 0.199574:  10%|#         | 2/20 [00:14<02:03,  6.88s/it]\u001b[32m[I 2021-05-22 18:54:09,080]\u001b[0m Trial 44 finished with value: 0.19987020488748977 and parameters: {'lambda_l1': 6.782471892288647e-06, 'lambda_l2': 1.7112843783837853e-08}. Best is trial 43 with value: 0.19957367190652828.\u001b[0m\n",
      "regularization_factors, val_score: 0.199574:  15%|#5        | 3/20 [00:21<01:57,  6.93s/it]\u001b[32m[I 2021-05-22 18:54:16,074]\u001b[0m Trial 45 finished with value: 0.19972040448575934 and parameters: {'lambda_l1': 0.019230272372914626, 'lambda_l2': 0.5637051837103557}. Best is trial 43 with value: 0.19957367190652828.\u001b[0m\n",
      "regularization_factors, val_score: 0.199574:  20%|##        | 4/20 [00:27<01:46,  6.67s/it]\u001b[32m[I 2021-05-22 18:54:22,346]\u001b[0m Trial 46 finished with value: 0.19987016649320802 and parameters: {'lambda_l1': 1.8540672274288212e-08, 'lambda_l2': 9.016758999672641e-06}. Best is trial 43 with value: 0.19957367190652828.\u001b[0m\n",
      "regularization_factors, val_score: 0.199574:  25%|##5       | 5/20 [00:33<01:38,  6.54s/it]\u001b[32m[I 2021-05-22 18:54:28,654]\u001b[0m Trial 47 finished with value: 0.19986993878720338 and parameters: {'lambda_l1': 1.8422763304842978e-08, 'lambda_l2': 5.3499395466007717e-05}. Best is trial 43 with value: 0.19957367190652828.\u001b[0m\n",
      "regularization_factors, val_score: 0.199574:  30%|###       | 6/20 [00:39<01:30,  6.48s/it]\u001b[32m[I 2021-05-22 18:54:35,023]\u001b[0m Trial 48 finished with value: 0.1998702016964996 and parameters: {'lambda_l1': 5.431857707778582e-07, 'lambda_l2': 1.139922647617167e-06}. Best is trial 43 with value: 0.19957367190652828.\u001b[0m\n",
      "regularization_factors, val_score: 0.199574:  35%|###5      | 7/20 [00:46<01:25,  6.59s/it]\u001b[32m[I 2021-05-22 18:54:41,821]\u001b[0m Trial 49 finished with value: 0.19975452124438797 and parameters: {'lambda_l1': 0.005711822365922218, 'lambda_l2': 0.2972343199697394}. Best is trial 43 with value: 0.19957367190652828.\u001b[0m\n",
      "regularization_factors, val_score: 0.199574:  40%|####      | 8/20 [00:53<01:18,  6.53s/it]\u001b[32m[I 2021-05-22 18:54:48,217]\u001b[0m Trial 50 finished with value: 0.19987019235674777 and parameters: {'lambda_l1': 5.542114485655267e-06, 'lambda_l2': 2.889317498801917e-06}. Best is trial 43 with value: 0.19957367190652828.\u001b[0m\n",
      "regularization_factors, val_score: 0.199574:  45%|####5     | 9/20 [00:59<01:11,  6.46s/it]\u001b[32m[I 2021-05-22 18:54:54,536]\u001b[0m Trial 51 finished with value: 0.1998702017107031 and parameters: {'lambda_l1': 1.3658496698004992e-05, 'lambda_l2': 2.704402729554223e-07}. Best is trial 43 with value: 0.19957367190652828.\u001b[0m\n",
      "regularization_factors, val_score: 0.199574:  50%|#####     | 10/20 [01:05<01:04,  6.47s/it]\u001b[32m[I 2021-05-22 18:55:01,034]\u001b[0m Trial 52 finished with value: 0.19987014200186745 and parameters: {'lambda_l1': 2.582521225758069e-08, 'lambda_l2': 1.4478195136557731e-05}. Best is trial 43 with value: 0.19957367190652828.\u001b[0m\n",
      "regularization_factors, val_score: 0.199574:  55%|#####5    | 11/20 [01:15<01:07,  7.50s/it]\u001b[32m[I 2021-05-22 18:55:10,855]\u001b[0m Trial 53 finished with value: 0.1997057709031859 and parameters: {'lambda_l1': 9.78091032182985, 'lambda_l2': 0.0074611024643731726}. Best is trial 43 with value: 0.19957367190652828.\u001b[0m\n",
      "regularization_factors, val_score: 0.199574:  60%|######    | 12/20 [01:23<01:00,  7.53s/it]\u001b[32m[I 2021-05-22 18:55:18,458]\u001b[0m Trial 54 finished with value: 0.199753732234198 and parameters: {'lambda_l1': 5.423051208633522, 'lambda_l2': 0.012670500170212212}. Best is trial 43 with value: 0.19957367190652828.\u001b[0m\n",
      "regularization_factors, val_score: 0.199574:  65%|######5   | 13/20 [01:32<00:55,  7.93s/it]\u001b[32m[I 2021-05-22 18:55:27,303]\u001b[0m Trial 55 finished with value: 0.19969439542427544 and parameters: {'lambda_l1': 5.926285649285118, 'lambda_l2': 0.002186285892568533}. Best is trial 43 with value: 0.19957367190652828.\u001b[0m\n",
      "regularization_factors, val_score: 0.199574:  70%|#######   | 14/20 [01:39<00:46,  7.67s/it]\u001b[32m[I 2021-05-22 18:55:34,387]\u001b[0m Trial 56 finished with value: 0.19983485777132956 and parameters: {'lambda_l1': 0.409850138426331, 'lambda_l2': 0.002048970580670522}. Best is trial 43 with value: 0.19957367190652828.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.199574:  75%|#######5  | 15/20 [01:46<00:37,  7.59s/it]\u001b[32m[I 2021-05-22 18:55:41,769]\u001b[0m Trial 57 finished with value: 0.19961117042948603 and parameters: {'lambda_l1': 0.3487957973770866, 'lambda_l2': 2.1261420723839746}. Best is trial 43 with value: 0.19957367190652828.\u001b[0m\n",
      "regularization_factors, val_score: 0.199574:  80%|########  | 16/20 [01:54<00:30,  7.59s/it]\u001b[32m[I 2021-05-22 18:55:49,382]\u001b[0m Trial 58 finished with value: 0.19959985584096218 and parameters: {'lambda_l1': 0.15083649271197724, 'lambda_l2': 5.060875710045474}. Best is trial 43 with value: 0.19957367190652828.\u001b[0m\n",
      "regularization_factors, val_score: 0.199437:  85%|########5 | 17/20 [02:02<00:23,  7.67s/it]\u001b[32m[I 2021-05-22 18:55:57,228]\u001b[0m Trial 59 finished with value: 0.19943667960479963 and parameters: {'lambda_l1': 0.0021162855817617346, 'lambda_l2': 9.484825815823141}. Best is trial 59 with value: 0.19943667960479963.\u001b[0m\n",
      "regularization_factors, val_score: 0.199437:  90%|######### | 18/20 [02:08<00:14,  7.35s/it]\u001b[32m[I 2021-05-22 18:56:03,835]\u001b[0m Trial 60 finished with value: 0.19974779904044812 and parameters: {'lambda_l1': 0.0003320476165792685, 'lambda_l2': 0.10212940996488261}. Best is trial 59 with value: 0.19943667960479963.\u001b[0m\n",
      "regularization_factors, val_score: 0.199437:  95%|#########5| 19/20 [02:16<00:07,  7.32s/it]\u001b[32m[I 2021-05-22 18:56:11,095]\u001b[0m Trial 61 finished with value: 0.19961970063416604 and parameters: {'lambda_l1': 0.0006641557163285655, 'lambda_l2': 8.600828545382024}. Best is trial 59 with value: 0.19943667960479963.\u001b[0m\n",
      "regularization_factors, val_score: 0.199437: 100%|##########| 20/20 [02:22<00:00,  7.06s/it]\u001b[32m[I 2021-05-22 18:56:17,527]\u001b[0m Trial 62 finished with value: 0.1998290695482925 and parameters: {'lambda_l1': 0.003912210637545124, 'lambda_l2': 0.08216746701789335}. Best is trial 59 with value: 0.19943667960479963.\u001b[0m\n",
      "regularization_factors, val_score: 0.199437: 100%|##########| 20/20 [02:22<00:00,  7.12s/it]\n",
      "min_data_in_leaf, val_score: 0.199437:  20%|##        | 1/5 [00:07<00:30,  7.51s/it]\u001b[32m[I 2021-05-22 18:56:25,049]\u001b[0m Trial 63 finished with value: 0.199601693215155 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.199601693215155.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.199437:  40%|####      | 2/5 [00:15<00:23,  7.86s/it]\u001b[32m[I 2021-05-22 18:56:33,151]\u001b[0m Trial 64 finished with value: 0.19947812942582863 and parameters: {'min_child_samples': 25}. Best is trial 64 with value: 0.19947812942582863.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.199437:  60%|######    | 3/5 [00:23<00:15,  7.97s/it]\u001b[32m[I 2021-05-22 18:56:41,256]\u001b[0m Trial 65 finished with value: 0.19945595739070773 and parameters: {'min_child_samples': 100}. Best is trial 65 with value: 0.19945595739070773.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.199386:  80%|########  | 4/5 [00:31<00:08,  8.02s/it]\u001b[32m[I 2021-05-22 18:56:49,338]\u001b[0m Trial 66 finished with value: 0.19938617897042646 and parameters: {'min_child_samples': 50}. Best is trial 66 with value: 0.19938617897042646.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.199386: 100%|##########| 5/5 [00:40<00:00,  8.21s/it]\u001b[32m[I 2021-05-22 18:56:57,905]\u001b[0m Trial 67 finished with value: 0.19967091449094967 and parameters: {'min_child_samples': 5}. Best is trial 66 with value: 0.19938617897042646.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.199386: 100%|##########| 5/5 [00:40<00:00,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.19938617897042646\n",
      "Best params: {'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'feature_pre_filter': False, 'lambda_l1': 0.0021162855817617346, 'lambda_l2': 9.484825815823141, 'num_leaves': 31, 'feature_fraction': 0.5, 'bagging_fraction': 0.840081722766568, 'bagging_freq': 3, 'min_child_samples': 50}\n",
      "  Params: \n",
      "    objective: binary\n",
      "    metric: binary_logloss\n",
      "    verbosity: -1\n",
      "    boosting_type: gbdt\n",
      "    feature_pre_filter: False\n",
      "    lambda_l1: 0.0021162855817617346\n",
      "    lambda_l2: 9.484825815823141\n",
      "    num_leaves: 31\n",
      "    feature_fraction: 0.5\n",
      "    bagging_fraction: 0.840081722766568\n",
      "    bagging_freq: 3\n",
      "    min_child_samples: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import optuna.integration.lightgbm as lgb\n",
    "\n",
    "\n",
    "dtrain = lgb.Dataset(X_25, label=y)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"verbosity\": -1,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "}\n",
    "\n",
    "tuner = lgb.LightGBMTunerCV(\n",
    "    params, dtrain, verbose_eval=0, early_stopping_rounds=100, folds=KFold(n_splits=3), show_progress_bar=True\n",
    ")\n",
    "\n",
    "tuner.run()\n",
    "\n",
    "print(\"Best score:\", tuner.best_score)\n",
    "best_params = tuner.best_params\n",
    "print(\"Best params:\", best_params)\n",
    "print(\"  Params: \")\n",
    "for key, value in best_params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.945 (0.002)\n"
     ]
    }
   ],
   "source": [
    "data_train = lgb.Dataset(X_25, label=y)\n",
    "params = best_params\n",
    "\n",
    "\n",
    "# evaluate the model\n",
    "\n",
    "model = LGBMClassifier()\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AML",
   "language": "python",
   "name": "aml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
