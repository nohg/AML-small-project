{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression using tree based algorithm\n",
    "\n",
    "Estimate (i.e. make regression for) the energy of electrons. This should be based on maximum 15 variables from the Electron Variable List. The target variable for this task is \"p_truth_E\": Energy (in GeV) of the electrons, and you should only train on real (i.e. truth identified, \"Truth==1\") electrons. Note: It is an advantage to ONLY train the regression on true electrons (Truth = 1), but when submitting the solution, the regression estimate should be applied to ALL candidates, as you don't (perfectly) know, which are electrons, and which are not. We evaluate algorithm performance by considering Mean Absolute Error (MAE) on relative estimate accuracy: (E_pred-E_true)/E_true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by opening the files and loading them into a Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(name):\n",
    "    with h5py.File(f'{name}.h5', 'r') as f:\n",
    "        return pandas.DataFrame(f[name][:])\n",
    "\n",
    "train = load_data('train')\n",
    "test  = load_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## temporarily use a fraction of the data to speed everything up\n",
    "#train=train.sample(frac = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can verify the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data set: (162500, 166)\n",
      "Shape of test data set: (160651, 164)\n"
     ]
    }
   ],
   "source": [
    "print (f'Shape of training data set: {train.shape}')\n",
    "print (f'Shape of test data set: {test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the test set contains 2 columns less: `Truth` and `p_truth_E`.\n",
    "    \n",
    "Then we copy the variable list from the course website <https://www.nbi.dk/~petersen/Teaching/ML2020/SmallProject/VariableList.html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_variables = ['actualInteractionsPerCrossing', 'averageInteractionsPerCrossing', 'correctedActualMu', 'correctedAverageMu', 'correctedScaledActualMu', 'correctedScaledAverageMu', 'NvtxReco', 'p_nTracks', 'p_pt_track', 'p_eta', 'p_phi', 'p_charge', 'p_qOverP', 'p_z0', 'p_d0', 'p_sigmad0', 'p_d0Sig', 'p_EptRatio', 'p_dPOverP', 'p_z0theta', 'p_etaCluster', 'p_phiCluster', 'p_eCluster', 'p_rawEtaCluster', 'p_rawPhiCluster', 'p_rawECluster', 'p_eClusterLr0', 'p_eClusterLr1', 'p_eClusterLr2', 'p_eClusterLr3', 'p_etaClusterLr1', 'p_etaClusterLr2', 'p_phiClusterLr2', 'p_eAccCluster', 'p_f0Cluster', 'p_etaCalo', 'p_phiCalo', 'p_eTileGap3Cluster', 'p_cellIndexCluster', 'p_phiModCalo', 'p_etaModCalo', 'p_dPhiTH3', 'p_R12', 'p_fTG3', 'p_weta2', 'p_Reta', 'p_Rphi', 'p_Eratio', 'p_f1', 'p_f3', 'p_Rhad', 'p_Rhad1', 'p_deltaEta1', 'p_deltaPhiRescaled2', 'p_TRTPID', 'p_TRTTrackOccupancy', 'p_numberOfInnermostPixelHits', 'p_numberOfPixelHits', 'p_numberOfSCTHits', 'p_numberOfTRTHits', 'p_numberOfTRTXenonHits', 'p_chi2', 'p_ndof', 'p_SharedMuonTrack', 'p_E7x7_Lr2', 'p_E7x7_Lr3', 'p_E_Lr0_HiG', 'p_E_Lr0_LowG', 'p_E_Lr0_MedG', 'p_E_Lr1_HiG', 'p_E_Lr1_LowG', 'p_E_Lr1_MedG', 'p_E_Lr2_HiG', 'p_E_Lr2_LowG', 'p_E_Lr2_MedG', 'p_E_Lr3_HiG', 'p_E_Lr3_LowG', 'p_E_Lr3_MedG', 'p_ambiguityType', 'p_asy1', 'p_author', 'p_barys1', 'p_core57cellsEnergyCorrection', 'p_deltaEta0', 'p_deltaEta2', 'p_deltaEta3', 'p_deltaPhi0', 'p_deltaPhi1', 'p_deltaPhi2', 'p_deltaPhi3', 'p_deltaPhiFromLastMeasurement', 'p_deltaPhiRescaled0', 'p_deltaPhiRescaled1', 'p_deltaPhiRescaled3', 'p_e1152', 'p_e132', 'p_e235', 'p_e255', 'p_e2ts1', 'p_ecore', 'p_emins1', 'p_etconeCorrBitset', 'p_ethad', 'p_ethad1', 'p_f1core', 'p_f3core', 'p_maxEcell_energy', 'p_maxEcell_gain', 'p_maxEcell_time', 'p_maxEcell_x', 'p_maxEcell_y', 'p_maxEcell_z', 'p_nCells_Lr0_HiG', 'p_nCells_Lr0_LowG', 'p_nCells_Lr0_MedG', 'p_nCells_Lr1_HiG', 'p_nCells_Lr1_LowG', 'p_nCells_Lr1_MedG', 'p_nCells_Lr2_HiG', 'p_nCells_Lr2_LowG', 'p_nCells_Lr2_MedG', 'p_nCells_Lr3_HiG', 'p_nCells_Lr3_LowG', 'p_nCells_Lr3_MedG', 'p_pos', 'p_pos7', 'p_poscs1', 'p_poscs2', 'p_ptconeCorrBitset', 'p_ptconecoreTrackPtrCorrection', 'p_r33over37allcalo', 'p_topoetconeCorrBitset', 'p_topoetconecoreConeEnergyCorrection', 'p_topoetconecoreConeSCEnergyCorrection', 'p_weta1', 'p_widths1', 'p_widths2', 'p_wtots1', 'p_e233', 'p_e237', 'p_e277', 'p_e2tsts1', 'p_ehad1', 'p_emaxs1', 'p_fracs1', 'p_DeltaE', 'p_E3x5_Lr0', 'p_E3x5_Lr1', 'p_E3x5_Lr2', 'p_E3x5_Lr3', 'p_E5x7_Lr0', 'p_E5x7_Lr1', 'p_E5x7_Lr2', 'p_E5x7_Lr3', 'p_E7x11_Lr0', 'p_E7x11_Lr1', 'p_E7x11_Lr2', 'p_E7x11_Lr3', 'p_E7x7_Lr0', 'p_E7x7_Lr1' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we divide the training data into data (`X`) and targets (`y`)\n",
    "\n",
    "Only use the entries which we know are true electrons for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (121495, 160)\n",
      "Shape of y: (121495,)\n"
     ]
    }
   ],
   "source": [
    "train = train.loc[train['Truth']==1]\n",
    "X = train[all_variables]\n",
    "y = train['p_truth_E']\n",
    "\n",
    "print (f'Shape of X: {X.shape}')\n",
    "print (f'Shape of y: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualInteractionsPerCrossing</th>\n",
       "      <th>averageInteractionsPerCrossing</th>\n",
       "      <th>correctedActualMu</th>\n",
       "      <th>correctedAverageMu</th>\n",
       "      <th>correctedScaledActualMu</th>\n",
       "      <th>correctedScaledAverageMu</th>\n",
       "      <th>NvtxReco</th>\n",
       "      <th>p_nTracks</th>\n",
       "      <th>p_pt_track</th>\n",
       "      <th>p_eta</th>\n",
       "      <th>...</th>\n",
       "      <th>p_E5x7_Lr0</th>\n",
       "      <th>p_E5x7_Lr1</th>\n",
       "      <th>p_E5x7_Lr2</th>\n",
       "      <th>p_E5x7_Lr3</th>\n",
       "      <th>p_E7x11_Lr0</th>\n",
       "      <th>p_E7x11_Lr1</th>\n",
       "      <th>p_E7x11_Lr2</th>\n",
       "      <th>p_E7x11_Lr3</th>\n",
       "      <th>p_E7x7_Lr0</th>\n",
       "      <th>p_E7x7_Lr1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>26.5</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>42011.792969</td>\n",
       "      <td>1.834715</td>\n",
       "      <td>...</td>\n",
       "      <td>215.588013</td>\n",
       "      <td>43402.332031</td>\n",
       "      <td>74045.820312</td>\n",
       "      <td>337.980713</td>\n",
       "      <td>273.708801</td>\n",
       "      <td>43091.683594</td>\n",
       "      <td>74447.539062</td>\n",
       "      <td>470.177124</td>\n",
       "      <td>273.708801</td>\n",
       "      <td>43091.683594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.5</td>\n",
       "      <td>37.5</td>\n",
       "      <td>37.5</td>\n",
       "      <td>37.5</td>\n",
       "      <td>37.5</td>\n",
       "      <td>37.5</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>44975.042969</td>\n",
       "      <td>-2.023659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27372.955078</td>\n",
       "      <td>104002.000000</td>\n",
       "      <td>921.178040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27101.673828</td>\n",
       "      <td>106995.789062</td>\n",
       "      <td>1127.115356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27101.673828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   actualInteractionsPerCrossing  averageInteractionsPerCrossing  \\\n",
       "0                           26.5                            26.5   \n",
       "3                           37.5                            37.5   \n",
       "\n",
       "   correctedActualMu  correctedAverageMu  correctedScaledActualMu  \\\n",
       "0               26.5                26.5                     26.5   \n",
       "3               37.5                37.5                     37.5   \n",
       "\n",
       "   correctedScaledAverageMu  NvtxReco  p_nTracks    p_pt_track     p_eta  ...  \\\n",
       "0                      26.5        18          3  42011.792969  1.834715  ...   \n",
       "3                      37.5        17          2  44975.042969 -2.023659  ...   \n",
       "\n",
       "   p_E5x7_Lr0    p_E5x7_Lr1     p_E5x7_Lr2  p_E5x7_Lr3  p_E7x11_Lr0  \\\n",
       "0  215.588013  43402.332031   74045.820312  337.980713   273.708801   \n",
       "3    0.000000  27372.955078  104002.000000  921.178040     0.000000   \n",
       "\n",
       "    p_E7x11_Lr1    p_E7x11_Lr2  p_E7x11_Lr3  p_E7x7_Lr0    p_E7x7_Lr1  \n",
       "0  43091.683594   74447.539062   470.177124  273.708801  43091.683594  \n",
       "3  27101.673828  106995.789062  1127.115356    0.000000  27101.673828  \n",
       "\n",
       "[2 rows x 160 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install seaborn update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x123856b50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(data=train, x=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eventNumber                       0\n",
       "runNumber                         0\n",
       "actualInteractionsPerCrossing     0\n",
       "averageInteractionsPerCrossing    0\n",
       "correctedActualMu                 0\n",
       "                                 ..\n",
       "p_E7x11_Lr2                       0\n",
       "p_E7x11_Lr3                       0\n",
       "p_E7x7_Lr0                        0\n",
       "p_E7x7_Lr1                        0\n",
       "index                             0\n",
       "Length: 166, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No nulls\n",
    "### Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_X = deepcopy(X) \n",
    "# This loop transforms every variable _independently_ \n",
    "for variable in X.columns:     \n",
    "    transformed_X[variable] = RobustScaler().fit_transform(np.array(transformed_X[variable]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select k Best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niallgray/opt/miniconda3/envs/aml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:301: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/niallgray/opt/miniconda3/envs/aml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:301: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/niallgray/opt/miniconda3/envs/aml/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:306: RuntimeWarning: invalid value encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(121495, 15)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_15 = SelectKBest(score_func=f_regression, k=15).fit_transform(X, y)\n",
    "X_15.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_15,y,test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MAE is 36932.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# \"Learn\" the mean from the training data\n",
    "mean_train = np.mean(y_train)\n",
    "# Get predictions on the test set\n",
    "baseline_predictions = np.ones(y_test.shape) * mean_train\n",
    "# Compute MAE\n",
    "mae_baseline = mean_absolute_error(y_test, baseline_predictions)\n",
    "print(\"Baseline MAE is {:.2f}\".format(mae_baseline))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -6641.574 (87.158)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints=None,\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "             validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xgboost for regression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "# evaluate the model\n",
    "model = XGBRegressor(objective='reg:squarederror')\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X_15, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('MAE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model = XGBRegressor(objective='reg:squarederror')\n",
    "model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -6548.651 (74.833)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "# evaluate the model\n",
    "model = LGBMRegressor()\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X_15, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('MAE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model = LGBMRegressor()\n",
    "model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 500 candidates, totalling 15000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   34.0s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed: 15.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed: 19.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed: 22.6min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed: 27.1min\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed: 31.7min\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed: 36.4min\n",
      "[Parallel(n_jobs=-1)]: Done 12784 tasks      | elapsed: 48.6min\n",
      "[Parallel(n_jobs=-1)]: Done 14434 tasks      | elapsed: 55.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -6462.42947586077\n",
      "Best Hyperparameters: {'alpha': 0.0002531181460133387, 'fit_intercept': True, 'normalize': True, 'solver': 'svd'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 15000 out of 15000 | elapsed: 57.1min finished\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import loguniform\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# define model\n",
    "model = Ridge()\n",
    "# define evaluation\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define search space\n",
    "space = dict()\n",
    "space['solver'] = ['svd', 'cholesky', 'lsqr', 'sag']\n",
    "space['alpha'] = loguniform(1e-5, 100)\n",
    "space['fit_intercept'] = [True, False]\n",
    "space['normalize'] = [True, False]\n",
    "# define search\n",
    "search = RandomizedSearchCV(model, space, n_iter=500, scoring='neg_mean_absolute_error', n_jobs=-1, cv=cv, random_state=1, verbose=1)\n",
    "# execute search\n",
    "result = search.fit(X_15, y)\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 128 candidates, totalling 3840 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   36.3s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3840 out of 3840 | elapsed: 14.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -6464.314837511495\n",
      "Best Hyperparameters: {'alpha': 0.0001, 'fit_intercept': True, 'normalize': True, 'solver': 'sag'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# define model\n",
    "model = Ridge()\n",
    "# define evaluation\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define search space\n",
    "space = dict()\n",
    "space['solver'] = ['svd', 'cholesky', 'lsqr', 'sag']\n",
    "space['alpha'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
    "space['fit_intercept'] = [True, False]\n",
    "space['normalize'] = [True, False]\n",
    "# define search\n",
    "search = GridSearchCV(model, space, scoring='neg_mean_absolute_error', n_jobs=-1, cv=cv, verbose=1)\n",
    "# execute search\n",
    "result = search.fit(X_15, y)\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 4 candidates, totalling 120 fits\n",
      "[17:46:25] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Best Score: -6529.302278645833\n",
      "Best Hyperparameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 700, 'silent': 1, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# define model\n",
    "model = XGBRegressor()\n",
    "# define evaluation\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define search space\n",
    "# parameters = {\n",
    "#               'objective':['reg:linear'],\n",
    "#               'learning_rate': [.03, 0.05, .07], #so called `eta` value\n",
    "#               'max_depth': [5, 6, 7],\n",
    "#               'min_child_weight': [4],\n",
    "#               'silent': [1],\n",
    "#               'subsample': [0.7],\n",
    "#               'colsample_bytree': [0.7],\n",
    "#               'n_estimators': [500]}\n",
    "parameters = {\n",
    "              #'objective':['reg:square'],\n",
    "              'learning_rate': [0.05], #so called `eta` value\n",
    "              'max_depth': [5],\n",
    "              'min_child_weight': [4],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.7],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [100, 300, 500, 700]}\n",
    "# define search\n",
    "search = GridSearchCV(model, parameters, scoring='neg_mean_absolute_error', n_jobs=-1, cv=cv, verbose=1)\n",
    "# execute search\n",
    "result = search.fit(X_15, y)\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "\n",
    "# #save your model or results\n",
    "# joblib.dump(search, 'XGBReg_gridsearch_result.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_result = joblib.load(\"XGBReg_gridsearch_result.pkl\")\n",
    "\n",
    "# # summarize result\n",
    "# print('Best Score: %s' % loaded_result.best_score_)\n",
    "# print('Best Hyperparameters: %s' % loaded_result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian optimisation of hyperparameters and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGB_CrossValidation(eta, learning_rate, max_depth, data, targets):\n",
    "    \"\"\"Decision Tree cross validation.\n",
    "       Fits a Decision Tree with the given paramaters to the target \n",
    "       given data, calculated a CV accuracy score and returns the mean.\n",
    "       The goal is to find combinations\n",
    "       that maximize the accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    estimator = XGBRegressor(n_estimators=n_estimators, learning_rate=learning_rate, \n",
    "                                 max_depth=max_depth, random_state=0)\n",
    "    \n",
    "    cval = cross_val_score(estimator, data, targets, scoring='accuracy', cv=5)\n",
    "    \n",
    "    return cval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_XGB(data, targets, pars, n_iter=5):\n",
    "    \"\"\"Apply Bayesian Optimization to Decision Tree parameters.\"\"\"\n",
    "    \n",
    "    def crossval_wrapper(n_estimators, learning_rate, max_depth):\n",
    "        \"\"\"Wrapper of Decision Tree cross validation. \n",
    "           max_depth and n_estimators\n",
    "           are cast to integer before we pass them along.\n",
    "        \"\"\"\n",
    "        return XGB_CrossValidation(n_estimators=int(n_estimators), \n",
    "                                            learning_rate=learning_rate, \n",
    "                                            max_depth=int(max_depth),\n",
    "                                            data=data, \n",
    "                                            targets=targets)\n",
    "\n",
    "    optimizer = BayesianOptimization(f=crossval_wrapper, \n",
    "                                     pbounds=pars, \n",
    "                                     random_state=42, \n",
    "                                     verbose=2)\n",
    "    optimizer.maximize(init_points=4, n_iter=n_iter)\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_BayesianOptimization = {\"learning_rate\": (0.0001, 1), \n",
    "                                   \"max_depth\": (1, 5),\n",
    "                                   \"n_estimators\": (50,500)\n",
    "                                  }\n",
    "\n",
    "BayesianOptimization = optimize_XGB(X_15, \n",
    "                                             y, \n",
    "                                             parameters_BayesianOptimization, \n",
    "                                             n_iter=5)\n",
    "print(BayesianOptimization.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'objective':['reg:linear'],\n",
    "              'learning_rate': [.03, 0.05, .07], #so called `eta` value\n",
    "              'max_depth': [5, 6, 7],\n",
    "              'min_child_weight': [4],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.7],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [500]}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AML",
   "language": "python",
   "name": "aml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
