{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression using tree based algorithm\n",
    "\n",
    "Estimate (i.e. make regression for) the energy of electrons. This should be based on maximum 15 variables from the Electron Variable List. The target variable for this task is \"p_truth_E\": Energy (in GeV) of the electrons, and you should only train on real (i.e. truth identified, \"Truth==1\") electrons. Note: It is an advantage to ONLY train the regression on true electrons (Truth = 1), but when submitting the solution, the regression estimate should be applied to ALL candidates, as you don't (perfectly) know, which are electrons, and which are not. We evaluate algorithm performance by considering Mean Absolute Error (MAE) on relative estimate accuracy: (E_pred-E_true)/E_true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by opening the files and loading them into a Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(name):\n",
    "    with h5py.File(f'{name}.h5', 'r') as f:\n",
    "        return pandas.DataFrame(f[name][:])\n",
    "\n",
    "train = load_data('train')\n",
    "test  = load_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## temporarily use a fraction of the data to speed everything up\n",
    "#train=train.sample(frac = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can verify the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data set: (162500, 166)\n",
      "Shape of test data set: (160651, 164)\n"
     ]
    }
   ],
   "source": [
    "print (f'Shape of training data set: {train.shape}')\n",
    "print (f'Shape of test data set: {test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the test set contains 2 columns less: `Truth` and `p_truth_E`.\n",
    "    \n",
    "Then we copy the variable list from the course website <https://www.nbi.dk/~petersen/Teaching/ML2020/SmallProject/VariableList.html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_variables = ['actualInteractionsPerCrossing', 'averageInteractionsPerCrossing', 'correctedActualMu', 'correctedAverageMu', 'correctedScaledActualMu', 'correctedScaledAverageMu', 'NvtxReco', 'p_nTracks', 'p_pt_track', 'p_eta', 'p_phi', 'p_charge', 'p_qOverP', 'p_z0', 'p_d0', 'p_sigmad0', 'p_d0Sig', 'p_EptRatio', 'p_dPOverP', 'p_z0theta', 'p_etaCluster', 'p_phiCluster', 'p_eCluster', 'p_rawEtaCluster', 'p_rawPhiCluster', 'p_rawECluster', 'p_eClusterLr0', 'p_eClusterLr1', 'p_eClusterLr2', 'p_eClusterLr3', 'p_etaClusterLr1', 'p_etaClusterLr2', 'p_phiClusterLr2', 'p_eAccCluster', 'p_f0Cluster', 'p_etaCalo', 'p_phiCalo', 'p_eTileGap3Cluster', 'p_cellIndexCluster', 'p_phiModCalo', 'p_etaModCalo', 'p_dPhiTH3', 'p_R12', 'p_fTG3', 'p_weta2', 'p_Reta', 'p_Rphi', 'p_Eratio', 'p_f1', 'p_f3', 'p_Rhad', 'p_Rhad1', 'p_deltaEta1', 'p_deltaPhiRescaled2', 'p_TRTPID', 'p_TRTTrackOccupancy', 'p_numberOfInnermostPixelHits', 'p_numberOfPixelHits', 'p_numberOfSCTHits', 'p_numberOfTRTHits', 'p_numberOfTRTXenonHits', 'p_chi2', 'p_ndof', 'p_SharedMuonTrack', 'p_E7x7_Lr2', 'p_E7x7_Lr3', 'p_E_Lr0_HiG', 'p_E_Lr0_LowG', 'p_E_Lr0_MedG', 'p_E_Lr1_HiG', 'p_E_Lr1_LowG', 'p_E_Lr1_MedG', 'p_E_Lr2_HiG', 'p_E_Lr2_LowG', 'p_E_Lr2_MedG', 'p_E_Lr3_HiG', 'p_E_Lr3_LowG', 'p_E_Lr3_MedG', 'p_ambiguityType', 'p_asy1', 'p_author', 'p_barys1', 'p_core57cellsEnergyCorrection', 'p_deltaEta0', 'p_deltaEta2', 'p_deltaEta3', 'p_deltaPhi0', 'p_deltaPhi1', 'p_deltaPhi2', 'p_deltaPhi3', 'p_deltaPhiFromLastMeasurement', 'p_deltaPhiRescaled0', 'p_deltaPhiRescaled1', 'p_deltaPhiRescaled3', 'p_e1152', 'p_e132', 'p_e235', 'p_e255', 'p_e2ts1', 'p_ecore', 'p_emins1', 'p_etconeCorrBitset', 'p_ethad', 'p_ethad1', 'p_f1core', 'p_f3core', 'p_maxEcell_energy', 'p_maxEcell_gain', 'p_maxEcell_time', 'p_maxEcell_x', 'p_maxEcell_y', 'p_maxEcell_z', 'p_nCells_Lr0_HiG', 'p_nCells_Lr0_LowG', 'p_nCells_Lr0_MedG', 'p_nCells_Lr1_HiG', 'p_nCells_Lr1_LowG', 'p_nCells_Lr1_MedG', 'p_nCells_Lr2_HiG', 'p_nCells_Lr2_LowG', 'p_nCells_Lr2_MedG', 'p_nCells_Lr3_HiG', 'p_nCells_Lr3_LowG', 'p_nCells_Lr3_MedG', 'p_pos', 'p_pos7', 'p_poscs1', 'p_poscs2', 'p_ptconeCorrBitset', 'p_ptconecoreTrackPtrCorrection', 'p_r33over37allcalo', 'p_topoetconeCorrBitset', 'p_topoetconecoreConeEnergyCorrection', 'p_topoetconecoreConeSCEnergyCorrection', 'p_weta1', 'p_widths1', 'p_widths2', 'p_wtots1', 'p_e233', 'p_e237', 'p_e277', 'p_e2tsts1', 'p_ehad1', 'p_emaxs1', 'p_fracs1', 'p_DeltaE', 'p_E3x5_Lr0', 'p_E3x5_Lr1', 'p_E3x5_Lr2', 'p_E3x5_Lr3', 'p_E5x7_Lr0', 'p_E5x7_Lr1', 'p_E5x7_Lr2', 'p_E5x7_Lr3', 'p_E7x11_Lr0', 'p_E7x11_Lr1', 'p_E7x11_Lr2', 'p_E7x11_Lr3', 'p_E7x7_Lr0', 'p_E7x7_Lr1' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we divide the training data into data (`X`) and targets (`y`)\n",
    "\n",
    "Only use the entries which we know are true electrons for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (121495, 160)\n",
      "Shape of y: (121495,)\n",
      "Shape of X_test: (160651, 160)\n"
     ]
    }
   ],
   "source": [
    "train = train.loc[train['Truth']==1]\n",
    "X = train[all_variables]\n",
    "y = train['p_truth_E']\n",
    "X_test = test[all_variables]\n",
    "\n",
    "\n",
    "\n",
    "print (f'Shape of X: {X.shape}')\n",
    "print (f'Shape of y: {y.shape}')\n",
    "print (f'Shape of X_test: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eventNumber',\n",
       " 'runNumber',\n",
       " 'actualInteractionsPerCrossing',\n",
       " 'averageInteractionsPerCrossing',\n",
       " 'correctedActualMu',\n",
       " 'correctedAverageMu',\n",
       " 'correctedScaledActualMu',\n",
       " 'correctedScaledAverageMu',\n",
       " 'NvtxReco',\n",
       " 'p_nTracks',\n",
       " 'p_pt_track',\n",
       " 'p_eta',\n",
       " 'p_phi',\n",
       " 'p_charge',\n",
       " 'p_qOverP',\n",
       " 'p_z0',\n",
       " 'p_d0',\n",
       " 'p_sigmad0',\n",
       " 'p_d0Sig',\n",
       " 'p_EptRatio',\n",
       " 'p_dPOverP',\n",
       " 'p_z0theta',\n",
       " 'p_deltaR_tag']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train.columns.to_numpy()[0:23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'p_deltaR_tag'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/envs/python3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'p_deltaR_tag'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-c8d9c1b264a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'p_deltaR_tag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/python3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2994\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2995\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2996\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2997\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'p_deltaR_tag'"
     ]
    }
   ],
   "source": [
    "X['p_deltaR_tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install seaborn update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'seaborn' has no attribute 'displot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b1f8c345d4f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'seaborn' has no attribute 'displot'"
     ]
    }
   ],
   "source": [
    "#sns.displot(data=train, x=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eventNumber                       0\n",
       "runNumber                         0\n",
       "actualInteractionsPerCrossing     0\n",
       "averageInteractionsPerCrossing    0\n",
       "correctedActualMu                 0\n",
       "                                 ..\n",
       "p_E7x11_Lr2                       0\n",
       "p_E7x11_Lr3                       0\n",
       "p_E7x7_Lr0                        0\n",
       "p_E7x7_Lr1                        0\n",
       "index                             0\n",
       "Length: 166, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No nulls\n",
    "### Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_X = deepcopy(X) \n",
    "transformed_X_test = deepcopy(X_test)\n",
    "# This loop transforms every variable _independently_ \n",
    "for variable in X.columns: \n",
    "    scaler = RobustScaler().fit(np.array(transformed_X[variable]).reshape(-1,1))\n",
    "    transformed_X[variable] = scaler.transform(np.array(transformed_X[variable]).reshape(-1,1))\n",
    "    transformed_X_test[variable] = scaler.transform(np.array(transformed_X_test[variable]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select k Best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['p_eCluster', 'p_rawECluster', 'p_eClusterLr2', 'p_eAccCluster',\n",
      "       'p_cellIndexCluster', 'p_E7x7_Lr2', 'p_e235', 'p_e255', 'p_ecore',\n",
      "       'p_e233', 'p_e237', 'p_e277', 'p_E3x5_Lr2', 'p_E5x7_Lr2',\n",
      "       'p_E7x11_Lr2'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.7/site-packages/sklearn/feature_selection/_univariate_selection.py:299: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/opt/conda/envs/python3/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in greater\n",
      "  return (a < x) & (x < b)\n",
      "/opt/conda/envs/python3/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in less\n",
      "  return (a < x) & (x < b)\n",
      "/opt/conda/envs/python3/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:1912: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= _a)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'transformed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-78a8254c83a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfeatures_df_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_df_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'p_deltaR_tag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'transformed' is not defined"
     ]
    }
   ],
   "source": [
    "# Create and fit selector\n",
    "selector = SelectKBest(score_func=f_regression, k=15)\n",
    "X_15 = selector.fit_transform(transformed_X, y)\n",
    "# Get columns to keep and create new dataframe with those only\n",
    "cols = selector.get_support(indices=True)\n",
    "features_df_new = X.iloc[:,cols]\n",
    "print(features_df_new.columns)\n",
    "print(transformed['p_deltaR_tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22, 25, 28, 33, 38, 64, 96, 97, 99, 138, 139, 140, 148, 152, 156]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_X_test_15 = selector.transform(transformed_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_15,y,test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MAE is 36932.93\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# \"Learn\" the mean from the training data\n",
    "mean_train = np.mean(y_train)\n",
    "# Get predictions on the test set\n",
    "baseline_predictions = np.ones(y_test.shape) * mean_train\n",
    "# Compute MAE\n",
    "mae_baseline = mean_absolute_error(y_test, baseline_predictions)\n",
    "print(\"Baseline MAE is {:.2f}\".format(mae_baseline))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -6640.915 (87.337)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints=None,\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "             validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xgboost for regression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "# evaluate the model\n",
    "model = XGBRegressor(objective='reg:squarederror')\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X_15, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('MAE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model = XGBRegressor(objective='reg:squarederror')\n",
    "model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -6549.066 (74.602)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "# evaluate the model\n",
    "model = LGBMRegressor()\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X_15, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('MAE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "# fit the model on the whole dataset\n",
    "model = LGBMRegressor()\n",
    "model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 500 candidates, totalling 15000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   34.0s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed: 15.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed: 19.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed: 22.6min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed: 27.1min\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed: 31.7min\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed: 36.4min\n",
      "[Parallel(n_jobs=-1)]: Done 12784 tasks      | elapsed: 48.6min\n",
      "[Parallel(n_jobs=-1)]: Done 14434 tasks      | elapsed: 55.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -6462.42947586077\n",
      "Best Hyperparameters: {'alpha': 0.0002531181460133387, 'fit_intercept': True, 'normalize': True, 'solver': 'svd'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 15000 out of 15000 | elapsed: 57.1min finished\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import loguniform\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# define model\n",
    "model = Ridge()\n",
    "# define evaluation\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define search space\n",
    "space = dict()\n",
    "space['solver'] = ['svd', 'cholesky', 'lsqr', 'sag']\n",
    "space['alpha'] = loguniform(1e-5, 100)\n",
    "space['fit_intercept'] = [True, False]\n",
    "space['normalize'] = [True, False]\n",
    "# define search\n",
    "search = RandomizedSearchCV(model, space, n_iter=500, scoring='neg_mean_absolute_error', n_jobs=-1, cv=cv, random_state=1, verbose=1)\n",
    "# execute search\n",
    "result = search.fit(X_15, y)\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search with Ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 128 candidates, totalling 3840 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   48.3s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3840 out of 3840 | elapsed:  6.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -6462.432799131628\n",
      "Best Hyperparameters: {'alpha': 10, 'fit_intercept': True, 'normalize': False, 'solver': 'sag'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# define model\n",
    "model = Ridge()\n",
    "# define evaluation\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define search space\n",
    "space = dict()\n",
    "space['solver'] = ['svd', 'cholesky', 'lsqr', 'sag']\n",
    "space['alpha'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
    "space['fit_intercept'] = [True, False]\n",
    "space['normalize'] = [True, False]\n",
    "# define search\n",
    "search = GridSearchCV(model, space, scoring='neg_mean_absolute_error', n_jobs=-1, cv=cv, verbose=1)\n",
    "# execute search\n",
    "result = search.fit(X_15, y)\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run algo on test data and make output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_predictions = result.predict(transformed_X_test_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 81924.0406545 ,  81442.00600737, 229469.74021438, ...,\n",
       "       124563.45705649, 101969.70699286, 154608.06305157])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df_ridge=pandas.DataFrame(ridge_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df_ridge.to_csv('solutions/Regression_NiallGray_ridge.txt',header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list=pandas.DataFrame(features_df_new.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list.to_csv('solutions/Regression_NiallGray_ridge_VariableList.txt',index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 4 candidates, totalling 120 fits\n",
      "[17:46:25] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Best Score: -6529.302278645833\n",
      "Best Hyperparameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 700, 'silent': 1, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# define model\n",
    "model = XGBRegressor()\n",
    "# define evaluation\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define search space\n",
    "# parameters = {\n",
    "#               'objective':['reg:linear'],\n",
    "#               'learning_rate': [.03, 0.05, .07], #so called `eta` value\n",
    "#               'max_depth': [5, 6, 7],\n",
    "#               'min_child_weight': [4],\n",
    "#               'silent': [1],\n",
    "#               'subsample': [0.7],\n",
    "#               'colsample_bytree': [0.7],\n",
    "#               'n_estimators': [500]}\n",
    "parameters = {\n",
    "              #'objective':['reg:square'],\n",
    "              'learning_rate': [0.05], #so called `eta` value\n",
    "              'max_depth': [5],\n",
    "              'min_child_weight': [4],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.7],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [100, 300, 500, 700]}\n",
    "# define search\n",
    "search = GridSearchCV(model, parameters, scoring='neg_mean_absolute_error', n_jobs=-1, cv=cv, verbose=1)\n",
    "# execute search\n",
    "result = search.fit(X_15, y)\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "\n",
    "# #save your model or results\n",
    "# joblib.dump(search, 'XGBReg_gridsearch_result.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_result = joblib.load(\"XGBReg_gridsearch_result.pkl\")\n",
    "\n",
    "# # summarize result\n",
    "# print('Best Score: %s' % loaded_result.best_score_)\n",
    "# print('Best Hyperparameters: %s' % loaded_result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian optimisation of hyperparameters and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGB_CrossValidation(n_estimators, learning_rate, max_depth, data, targets):\n",
    "    \"\"\"Decision Tree cross validation.\n",
    "       Fits a Decision Tree with the given paramaters to the target \n",
    "       given data, calculated a CV accuracy score and returns the mean.\n",
    "       The goal is to find combinations\n",
    "       that maximize the accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    estimator = XGBRegressor(n_estimators=n_estimators, learning_rate=learning_rate, \n",
    "                                 max_depth=max_depth, random_state=0)\n",
    "    \n",
    "    cval = cross_val_score(estimator, data, targets, scoring='neg_mean_absolute_error', cv=5)\n",
    "    \n",
    "    return cval.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_XGB(data, targets, pars, n_iter=5):\n",
    "    \"\"\"Apply Bayesian Optimization to Decision Tree parameters.\"\"\"\n",
    "    \n",
    "    def crossval_wrapper(n_estimators, learning_rate, max_depth):\n",
    "        \"\"\"Wrapper of Decision Tree cross validation. \n",
    "           max_depth and n_estimators\n",
    "           are cast to integer before we pass them along.\n",
    "        \"\"\"\n",
    "        return XGB_CrossValidation(n_estimators=int(n_estimators), \n",
    "                                            learning_rate=learning_rate, \n",
    "                                            max_depth=int(max_depth),\n",
    "                                            data=data, \n",
    "                                            targets=targets)\n",
    "\n",
    "    optimizer = BayesianOptimization(f=crossval_wrapper, \n",
    "                                     pbounds=pars, \n",
    "                                     random_state=42, \n",
    "                                     verbose=2)\n",
    "    optimizer.maximize(init_points=4, n_iter=n_iter)\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learni... | max_depth | n_esti... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-6.796e+0\u001b[0m | \u001b[0m 0.3746  \u001b[0m | \u001b[0m 4.803   \u001b[0m | \u001b[0m 379.4   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-7.415e+0\u001b[0m | \u001b[0m 0.5987  \u001b[0m | \u001b[0m 1.624   \u001b[0m | \u001b[0m 120.2   \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m-6.554e+0\u001b[0m | \u001b[95m 0.05818 \u001b[0m | \u001b[95m 4.465   \u001b[0m | \u001b[95m 320.5   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-6.795e+0\u001b[0m | \u001b[0m 0.7081  \u001b[0m | \u001b[0m 1.082   \u001b[0m | \u001b[0m 486.5   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-6.557e+0\u001b[0m | \u001b[0m 0.05821 \u001b[0m | \u001b[0m 4.464   \u001b[0m | \u001b[0m 320.8   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-6.556e+0\u001b[0m | \u001b[0m 0.05601 \u001b[0m | \u001b[0m 4.487   \u001b[0m | \u001b[0m 320.5   \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m-6.547e+0\u001b[0m | \u001b[95m 0.06988 \u001b[0m | \u001b[95m 4.346   \u001b[0m | \u001b[95m 320.6   \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m-6.544e+0\u001b[0m | \u001b[95m 0.07397 \u001b[0m | \u001b[95m 4.361   \u001b[0m | \u001b[95m 320.6   \u001b[0m |\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m-6.541e+0\u001b[0m | \u001b[95m 0.08543 \u001b[0m | \u001b[95m 4.448   \u001b[0m | \u001b[95m 320.6   \u001b[0m |\n",
      "=============================================================\n",
      "{'target': -6541.25009765625, 'params': {'learning_rate': 0.08542670589514904, 'max_depth': 4.447924067040249, 'n_estimators': 320.643131210903}}\n"
     ]
    }
   ],
   "source": [
    "parameters_BayesianOptimization = {\"learning_rate\": (0.0001, 1), \n",
    "                                   \"max_depth\": (1, 5),\n",
    "                                   \"n_estimators\": (50,500)\n",
    "                                  }\n",
    "\n",
    "BayesianOptimization = optimize_XGB(X_15, \n",
    "                                             y, \n",
    "                                             parameters_BayesianOptimization, \n",
    "                                             n_iter=5)\n",
    "print(BayesianOptimization.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'objective':['reg:linear'],\n",
    "#               'learning_rate': [.03, 0.05, .07], #so called `eta` value\n",
    "#               'max_depth': [5, 6, 7],\n",
    "#               'min_child_weight': [4],\n",
    "#               'silent': [1],\n",
    "#               'subsample': [0.7],\n",
    "#               'colsample_bytree': [0.7],\n",
    "#               'n_estimators': [500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-05-22 21:10:09,528]\u001b[0m A new study created in memory with name: no-name-fa2758bd-f39d-42c8-8347-75ce0e2fed42\u001b[0m\n",
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.000000:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.000000:  14%|#4        | 1/7 [00:00<00:03,  1.84it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:10,081]\u001b[0m Trial 0 finished with value: 0.0 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "feature_fraction, val_score: 0.000000:  14%|#4        | 1/7 [00:00<00:03,  1.84it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.000000:  14%|#4        | 1/7 [00:01<00:03,  1.84it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.000000:  29%|##8       | 2/7 [00:01<00:02,  1.85it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:10,618]\u001b[0m Trial 1 finished with value: 0.0 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "feature_fraction, val_score: 0.000000:  29%|##8       | 2/7 [00:01<00:02,  1.85it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.000000:  29%|##8       | 2/7 [00:01<00:02,  1.85it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.000000:  43%|####2     | 3/7 [00:01<00:02,  1.85it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:11,157]\u001b[0m Trial 2 finished with value: 0.0 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "feature_fraction, val_score: 0.000000:  43%|####2     | 3/7 [00:01<00:02,  1.85it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.000000:  43%|####2     | 3/7 [00:02<00:02,  1.85it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.000000:  57%|#####7    | 4/7 [00:02<00:01,  1.85it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:11,694]\u001b[0m Trial 3 finished with value: 0.0 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "feature_fraction, val_score: 0.000000:  57%|#####7    | 4/7 [00:02<00:01,  1.85it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.000000:  57%|#####7    | 4/7 [00:02<00:01,  1.85it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.000000:  71%|#######1  | 5/7 [00:02<00:01,  1.86it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:12,226]\u001b[0m Trial 4 finished with value: 0.0 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "feature_fraction, val_score: 0.000000:  71%|#######1  | 5/7 [00:02<00:01,  1.86it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.000000:  71%|#######1  | 5/7 [00:03<00:01,  1.86it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.000000:  86%|########5 | 6/7 [00:03<00:00,  1.87it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:12,754]\u001b[0m Trial 5 finished with value: 0.0 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "\n",
      "feature_fraction, val_score: 0.000000:  86%|########5 | 6/7 [00:03<00:00,  1.87it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.000000:  86%|########5 | 6/7 [00:03<00:00,  1.87it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.000000: 100%|##########| 7/7 [00:03<00:00,  1.87it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:13,288]\u001b[0m Trial 6 finished with value: 0.0 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.0.\u001b[0m\n",
      "feature_fraction, val_score: 0.000000: 100%|##########| 7/7 [00:03<00:00,  1.86it/s]\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:   5%|5         | 1/20 [00:00<00:10,  1.88it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:13,828]\u001b[0m Trial 7 finished with value: 0.0 and parameters: {'num_leaves': 21}. Best is trial 7 with value: 0.0.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.000000:   5%|5         | 1/20 [00:00<00:10,  1.88it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:   5%|5         | 1/20 [00:01<00:10,  1.88it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  10%|#         | 2/20 [00:01<00:09,  1.83it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:14,412]\u001b[0m Trial 8 finished with value: 0.0 and parameters: {'num_leaves': 222}. Best is trial 7 with value: 0.0.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.000000:  10%|#         | 2/20 [00:01<00:09,  1.83it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  10%|#         | 2/20 [00:01<00:09,  1.83it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  15%|#5        | 3/20 [00:01<00:09,  1.86it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:14,931]\u001b[0m Trial 9 finished with value: 0.0 and parameters: {'num_leaves': 82}. Best is trial 7 with value: 0.0.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.000000:  15%|#5        | 3/20 [00:01<00:09,  1.86it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  15%|#5        | 3/20 [00:02<00:09,  1.86it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  20%|##        | 4/20 [00:02<00:08,  1.86it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:15,467]\u001b[0m Trial 10 finished with value: 0.0 and parameters: {'num_leaves': 129}. Best is trial 7 with value: 0.0.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.000000:  20%|##        | 4/20 [00:02<00:08,  1.86it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  20%|##        | 4/20 [00:02<00:08,  1.86it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  25%|##5       | 5/20 [00:02<00:08,  1.87it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:15,998]\u001b[0m Trial 11 finished with value: 0.0 and parameters: {'num_leaves': 131}. Best is trial 7 with value: 0.0.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.000000:  25%|##5       | 5/20 [00:02<00:08,  1.87it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  25%|##5       | 5/20 [00:03<00:08,  1.87it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  30%|###       | 6/20 [00:03<00:07,  1.87it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:16,528]\u001b[0m Trial 12 finished with value: 0.0 and parameters: {'num_leaves': 240}. Best is trial 7 with value: 0.0.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.000000:  30%|###       | 6/20 [00:03<00:07,  1.87it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  30%|###       | 6/20 [00:03<00:07,  1.87it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  35%|###5      | 7/20 [00:03<00:06,  1.89it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:17,048]\u001b[0m Trial 13 finished with value: 0.0 and parameters: {'num_leaves': 100}. Best is trial 7 with value: 0.0.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.000000:  35%|###5      | 7/20 [00:03<00:06,  1.89it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  35%|###5      | 7/20 [00:04<00:06,  1.89it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  40%|####      | 8/20 [00:04<00:06,  1.89it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:17,576]\u001b[0m Trial 14 finished with value: 0.0 and parameters: {'num_leaves': 106}. Best is trial 7 with value: 0.0.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.000000:  40%|####      | 8/20 [00:04<00:06,  1.89it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  40%|####      | 8/20 [00:04<00:06,  1.89it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  45%|####5     | 9/20 [00:04<00:05,  1.88it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:18,115]\u001b[0m Trial 15 finished with value: 0.0 and parameters: {'num_leaves': 89}. Best is trial 7 with value: 0.0.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.000000:  45%|####5     | 9/20 [00:04<00:05,  1.88it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  45%|####5     | 9/20 [00:05<00:05,  1.88it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  50%|#####     | 10/20 [00:05<00:05,  1.88it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:18,645]\u001b[0m Trial 16 finished with value: 0.0 and parameters: {'num_leaves': 41}. Best is trial 7 with value: 0.0.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.000000:  50%|#####     | 10/20 [00:05<00:05,  1.88it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  50%|#####     | 10/20 [00:05<00:05,  1.88it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  55%|#####5    | 11/20 [00:05<00:04,  1.88it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:19,183]\u001b[0m Trial 17 finished with value: 0.0 and parameters: {'num_leaves': 14}. Best is trial 7 with value: 0.0.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.000000:  55%|#####5    | 11/20 [00:05<00:04,  1.88it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  55%|#####5    | 11/20 [00:06<00:04,  1.88it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  60%|######    | 12/20 [00:06<00:04,  1.86it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:19,727]\u001b[0m Trial 18 finished with value: 0.0 and parameters: {'num_leaves': 237}. Best is trial 7 with value: 0.0.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.000000:  60%|######    | 12/20 [00:06<00:04,  1.86it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  60%|######    | 12/20 [00:06<00:04,  1.86it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  65%|######5   | 13/20 [00:06<00:03,  1.88it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:20,252]\u001b[0m Trial 19 finished with value: 0.0 and parameters: {'num_leaves': 183}. Best is trial 7 with value: 0.0.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.000000:  65%|######5   | 13/20 [00:06<00:03,  1.88it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  65%|######5   | 13/20 [00:07<00:03,  1.88it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  70%|#######   | 14/20 [00:07<00:03,  1.86it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:20,803]\u001b[0m Trial 20 finished with value: 0.0 and parameters: {'num_leaves': 181}. Best is trial 7 with value: 0.0.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.000000:  70%|#######   | 14/20 [00:07<00:03,  1.86it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  70%|#######   | 14/20 [00:08<00:03,  1.86it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  75%|#######5  | 15/20 [00:08<00:02,  1.85it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:21,348]\u001b[0m Trial 21 finished with value: 0.0 and parameters: {'num_leaves': 194}. Best is trial 7 with value: 0.0.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.000000:  75%|#######5  | 15/20 [00:08<00:02,  1.85it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  75%|#######5  | 15/20 [00:08<00:02,  1.85it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  80%|########  | 16/20 [00:08<00:02,  1.86it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:21,875]\u001b[0m Trial 22 finished with value: 0.0 and parameters: {'num_leaves': 3}. Best is trial 7 with value: 0.0.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.000000:  80%|########  | 16/20 [00:08<00:02,  1.86it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  80%|########  | 16/20 [00:09<00:02,  1.86it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  85%|########5 | 17/20 [00:09<00:01,  1.87it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:22,405]\u001b[0m Trial 23 finished with value: 0.0 and parameters: {'num_leaves': 50}. Best is trial 7 with value: 0.0.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.000000:  85%|########5 | 17/20 [00:09<00:01,  1.87it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  85%|########5 | 17/20 [00:09<00:01,  1.87it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  90%|######### | 18/20 [00:09<00:01,  1.88it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:22,927]\u001b[0m Trial 24 finished with value: 0.0 and parameters: {'num_leaves': 171}. Best is trial 7 with value: 0.0.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.000000:  90%|######### | 18/20 [00:09<00:01,  1.88it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  90%|######### | 18/20 [00:10<00:01,  1.88it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  95%|#########5| 19/20 [00:10<00:00,  1.89it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:23,451]\u001b[0m Trial 25 finished with value: 0.0 and parameters: {'num_leaves': 2}. Best is trial 7 with value: 0.0.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.000000:  95%|#########5| 19/20 [00:10<00:00,  1.89it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000:  95%|#########5| 19/20 [00:10<00:00,  1.89it/s]\u001b[A\n",
      "num_leaves, val_score: 0.000000: 100%|##########| 20/20 [00:10<00:00,  1.88it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:23,987]\u001b[0m Trial 26 finished with value: 0.0 and parameters: {'num_leaves': 37}. Best is trial 7 with value: 0.0.\u001b[0m\n",
      "num_leaves, val_score: 0.000000: 100%|##########| 20/20 [00:10<00:00,  1.87it/s]\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "bagging, val_score: 0.000000:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "bagging, val_score: 0.000000:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "bagging, val_score: 0.000000:  10%|#         | 1/10 [00:00<00:05,  1.61it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:24,619]\u001b[0m Trial 27 finished with value: 0.0 and parameters: {'bagging_fraction': 0.5401020803964626, 'bagging_freq': 5}. Best is trial 27 with value: 0.0.\u001b[0m\n",
      "\n",
      "bagging, val_score: 0.000000:  10%|#         | 1/10 [00:00<00:05,  1.61it/s]\u001b[A\n",
      "bagging, val_score: 0.000000:  10%|#         | 1/10 [00:01<00:05,  1.61it/s]\u001b[A\n",
      "bagging, val_score: 0.000000:  20%|##        | 2/10 [00:01<00:05,  1.59it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:25,259]\u001b[0m Trial 28 finished with value: 0.0 and parameters: {'bagging_fraction': 0.7532559935431942, 'bagging_freq': 6}. Best is trial 27 with value: 0.0.\u001b[0m\n",
      "\n",
      "bagging, val_score: 0.000000:  20%|##        | 2/10 [00:01<00:05,  1.59it/s]\u001b[A\n",
      "bagging, val_score: 0.000000:  20%|##        | 2/10 [00:01<00:05,  1.59it/s]\u001b[A\n",
      "bagging, val_score: 0.000000:  30%|###       | 3/10 [00:01<00:04,  1.58it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:25,904]\u001b[0m Trial 29 finished with value: 0.0 and parameters: {'bagging_fraction': 0.9607949150019035, 'bagging_freq': 6}. Best is trial 27 with value: 0.0.\u001b[0m\n",
      "\n",
      "bagging, val_score: 0.000000:  30%|###       | 3/10 [00:01<00:04,  1.58it/s]\u001b[A\n",
      "bagging, val_score: 0.000000:  30%|###       | 3/10 [00:02<00:04,  1.58it/s]\u001b[A\n",
      "bagging, val_score: 0.000000:  40%|####      | 4/10 [00:02<00:03,  1.56it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:26,558]\u001b[0m Trial 30 finished with value: 0.0 and parameters: {'bagging_fraction': 0.9419611404330345, 'bagging_freq': 1}. Best is trial 27 with value: 0.0.\u001b[0m\n",
      "\n",
      "bagging, val_score: 0.000000:  40%|####      | 4/10 [00:02<00:03,  1.56it/s]\u001b[A\n",
      "bagging, val_score: 0.000000:  40%|####      | 4/10 [00:03<00:03,  1.56it/s]\u001b[A\n",
      "bagging, val_score: 0.000000:  50%|#####     | 5/10 [00:03<00:03,  1.57it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:27,195]\u001b[0m Trial 31 finished with value: 0.0 and parameters: {'bagging_fraction': 0.8430396649089613, 'bagging_freq': 7}. Best is trial 27 with value: 0.0.\u001b[0m\n",
      "\n",
      "bagging, val_score: 0.000000:  50%|#####     | 5/10 [00:03<00:03,  1.57it/s]\u001b[A\n",
      "bagging, val_score: 0.000000:  50%|#####     | 5/10 [00:03<00:03,  1.57it/s]\u001b[A\n",
      "bagging, val_score: 0.000000:  60%|######    | 6/10 [00:03<00:02,  1.59it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:27,804]\u001b[0m Trial 32 finished with value: 0.0 and parameters: {'bagging_fraction': 0.44783769774072685, 'bagging_freq': 1}. Best is trial 27 with value: 0.0.\u001b[0m\n",
      "\n",
      "bagging, val_score: 0.000000:  60%|######    | 6/10 [00:03<00:02,  1.59it/s]\u001b[A\n",
      "bagging, val_score: 0.000000:  60%|######    | 6/10 [00:04<00:02,  1.59it/s]\u001b[A\n",
      "bagging, val_score: 0.000000:  70%|#######   | 7/10 [00:04<00:01,  1.60it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:28,420]\u001b[0m Trial 33 finished with value: 0.0 and parameters: {'bagging_fraction': 0.5390611694363632, 'bagging_freq': 7}. Best is trial 27 with value: 0.0.\u001b[0m\n",
      "\n",
      "bagging, val_score: 0.000000:  70%|#######   | 7/10 [00:04<00:01,  1.60it/s]\u001b[A\n",
      "bagging, val_score: 0.000000:  70%|#######   | 7/10 [00:05<00:01,  1.60it/s]\u001b[A\n",
      "bagging, val_score: 0.000000:  80%|########  | 8/10 [00:05<00:01,  1.62it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:29,023]\u001b[0m Trial 34 finished with value: 0.0 and parameters: {'bagging_fraction': 0.47212016819577324, 'bagging_freq': 7}. Best is trial 27 with value: 0.0.\u001b[0m\n",
      "\n",
      "bagging, val_score: 0.000000:  80%|########  | 8/10 [00:05<00:01,  1.62it/s]\u001b[A\n",
      "bagging, val_score: 0.000000:  80%|########  | 8/10 [00:05<00:01,  1.62it/s]\u001b[A\n",
      "bagging, val_score: 0.000000:  90%|######### | 9/10 [00:05<00:00,  1.61it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:29,647]\u001b[0m Trial 35 finished with value: 0.0 and parameters: {'bagging_fraction': 0.7462303922962626, 'bagging_freq': 1}. Best is trial 27 with value: 0.0.\u001b[0m\n",
      "\n",
      "bagging, val_score: 0.000000:  90%|######### | 9/10 [00:05<00:00,  1.61it/s]\u001b[A\n",
      "bagging, val_score: 0.000000:  90%|######### | 9/10 [00:06<00:00,  1.61it/s]\u001b[A\n",
      "bagging, val_score: 0.000000: 100%|##########| 10/10 [00:06<00:00,  1.62it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:30,259]\u001b[0m Trial 36 finished with value: 0.0 and parameters: {'bagging_fraction': 0.6112645201541826, 'bagging_freq': 1}. Best is trial 27 with value: 0.0.\u001b[0m\n",
      "bagging, val_score: 0.000000: 100%|##########| 10/10 [00:06<00:00,  1.60it/s]\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.000000:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.000000:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.000000:  33%|###3      | 1/3 [00:00<00:01,  1.97it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:30,776]\u001b[0m Trial 37 finished with value: 0.0 and parameters: {'feature_fraction': 0.92}. Best is trial 37 with value: 0.0.\u001b[0m\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.000000:  33%|###3      | 1/3 [00:00<00:01,  1.97it/s]\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.000000:  33%|###3      | 1/3 [00:01<00:01,  1.97it/s]\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.000000:  67%|######6   | 2/3 [00:01<00:00,  1.97it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:31,284]\u001b[0m Trial 38 finished with value: 0.0 and parameters: {'feature_fraction': 0.9520000000000001}. Best is trial 37 with value: 0.0.\u001b[0m\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.000000:  67%|######6   | 2/3 [00:01<00:00,  1.97it/s]\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.000000:  67%|######6   | 2/3 [00:01<00:00,  1.97it/s]\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.000000: 100%|##########| 3/3 [00:01<00:00,  1.96it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:31,803]\u001b[0m Trial 39 finished with value: 0.0 and parameters: {'feature_fraction': 0.9840000000000001}. Best is trial 37 with value: 0.0.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.000000: 100%|##########| 3/3 [00:01<00:00,  1.95it/s]\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.000000:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.000000:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.000000:   5%|5         | 1/20 [00:00<00:09,  1.93it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:32,329]\u001b[0m Trial 40 finished with value: 0.0 and parameters: {'lambda_l1': 5.6638996257809365e-05, 'lambda_l2': 0.00023436846454271779}. Best is trial 40 with value: 0.0.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.000000:   5%|5         | 1/20 [00:00<00:09,  1.93it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.000000:   5%|5         | 1/20 [00:01<00:09,  1.93it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.000000:  10%|#         | 2/20 [00:01<00:09,  1.92it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:32,854]\u001b[0m Trial 41 finished with value: 0.0 and parameters: {'lambda_l1': 3.612255564081758e-05, 'lambda_l2': 0.0013579854808233552}. Best is trial 40 with value: 0.0.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.000000:  10%|#         | 2/20 [00:01<00:09,  1.92it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.000000:  10%|#         | 2/20 [00:01<00:09,  1.92it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.000000:  15%|#5        | 3/20 [00:01<00:08,  1.92it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:33,374]\u001b[0m Trial 42 finished with value: 0.0 and parameters: {'lambda_l1': 1.831822025393325e-07, 'lambda_l2': 0.013335503636470307}. Best is trial 40 with value: 0.0.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.000000:  15%|#5        | 3/20 [00:01<00:08,  1.92it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.000000:  15%|#5        | 3/20 [00:02<00:08,  1.92it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.000000:  20%|##        | 4/20 [00:02<00:08,  1.93it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:33,887]\u001b[0m Trial 43 finished with value: 0.0 and parameters: {'lambda_l1': 6.010166952816038, 'lambda_l2': 4.233448446958436e-08}. Best is trial 40 with value: 0.0.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.000000:  20%|##        | 4/20 [00:02<00:08,  1.93it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.000000:  20%|##        | 4/20 [00:02<00:08,  1.93it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.000000:  25%|##5       | 5/20 [00:02<00:07,  1.93it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:34,410]\u001b[0m Trial 44 finished with value: 0.0 and parameters: {'lambda_l1': 7.501848329229282e-06, 'lambda_l2': 0.00017619186227079092}. Best is trial 40 with value: 0.0.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.000000:  25%|##5       | 5/20 [00:02<00:07,  1.93it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.000000:  25%|##5       | 5/20 [00:03<00:07,  1.93it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.000000:  30%|###       | 6/20 [00:03<00:07,  1.93it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:34,927]\u001b[0m Trial 45 finished with value: 0.0 and parameters: {'lambda_l1': 0.016206024169089384, 'lambda_l2': 0.7658672640498173}. Best is trial 40 with value: 0.0.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.000000:  30%|###       | 6/20 [00:03<00:07,  1.93it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.000000:  30%|###       | 6/20 [00:03<00:07,  1.93it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.000000:  35%|###5      | 7/20 [00:03<00:06,  1.93it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:35,446]\u001b[0m Trial 46 finished with value: 0.0 and parameters: {'lambda_l1': 0.006034348753660899, 'lambda_l2': 3.6977940844854422}. Best is trial 40 with value: 0.0.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.000000:  35%|###5      | 7/20 [00:03<00:06,  1.93it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.000000:  35%|###5      | 7/20 [00:04<00:06,  1.93it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.000000:  40%|####      | 8/20 [00:04<00:06,  1.93it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:35,963]\u001b[0m Trial 47 finished with value: 0.0 and parameters: {'lambda_l1': 0.684643102695107, 'lambda_l2': 2.082088822048881e-07}. Best is trial 40 with value: 0.0.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.000000:  40%|####      | 8/20 [00:04<00:06,  1.93it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.000000:  40%|####      | 8/20 [00:04<00:06,  1.93it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.000000:  45%|####5     | 9/20 [00:04<00:05,  1.94it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:36,469]\u001b[0m Trial 48 finished with value: 0.0 and parameters: {'lambda_l1': 2.3960744814927274e-07, 'lambda_l2': 6.239889722146165e-06}. Best is trial 40 with value: 0.0.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.000000:  45%|####5     | 9/20 [00:04<00:05,  1.94it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.000000:  45%|####5     | 9/20 [00:05<00:05,  1.94it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.000000:  50%|#####     | 10/20 [00:05<00:05,  1.95it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:36,982]\u001b[0m Trial 49 finished with value: 0.0 and parameters: {'lambda_l1': 4.137493505708567e-06, 'lambda_l2': 0.0006780151005496951}. Best is trial 40 with value: 0.0.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.000000:  50%|#####     | 10/20 [00:05<00:05,  1.95it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.000000:  50%|#####     | 10/20 [00:05<00:05,  1.95it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.000000:  55%|#####5    | 11/20 [00:05<00:04,  1.93it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:37,505]\u001b[0m Trial 50 finished with value: 0.0 and parameters: {'lambda_l1': 0.0008980176049632055, 'lambda_l2': 5.857373827270678e-06}. Best is trial 40 with value: 0.0.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.000000:  55%|#####5    | 11/20 [00:05<00:04,  1.93it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.000000:  55%|#####5    | 11/20 [00:06<00:04,  1.93it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.000000:  60%|######    | 12/20 [00:06<00:04,  1.93it/s]\u001b[A\u001b[32m[I 2021-05-22 21:10:38,025]\u001b[0m Trial 51 finished with value: 0.0 and parameters: {'lambda_l1': 3.451566587131028e-05, 'lambda_l2': 0.026904378170815875}. Best is trial 40 with value: 0.0.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.000000:  60%|######    | 12/20 [00:06<00:04,  1.93it/s]\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-ff6dbc5811de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python3/lib/python3.7/site-packages/optuna/integration/_lightgbm_tuner/optimize.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune_bagging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune_feature_fraction_stage2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune_regularization_factors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune_min_data_in_leaf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python3/lib/python3.7/site-packages/optuna/integration/_lightgbm_tuner/optimize.py\u001b[0m in \u001b[0;36mtune_regularization_factors\u001b[0;34m(self, n_trials)\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m             \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m             \u001b[0;34m\"regularization_factors\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         )\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python3/lib/python3.7/site-packages/optuna/integration/_lightgbm_tuner/optimize.py\u001b[0m in \u001b[0;36m_tune_params\u001b[0;34m(self, target_param_names, n_trials, sampler, step_name)\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m                 \u001b[0mcatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optuna_callbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m             )\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python3/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python3/lib/python3.7/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python3/lib/python3.7/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python3/lib/python3.7/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python3/lib/python3.7/site-packages/optuna/integration/_lightgbm_tuner/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0mcv_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgbm_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgbm_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mval_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_cv_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python3/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, fpreproc, verbose_eval, show_stdv, seed, callbacks, eval_train_metric)\u001b[0m\n\u001b[1;32m    533\u001b[0m                             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpreproc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfpreproc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m                             \u001b[0mstratified\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratified\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m                             eval_train_metric=eval_train_metric)\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;31m# setup callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python3/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36m_make_n_folds\u001b[0;34m(full_data, folds, nfold, params, seed, fpreproc, stratified, shuffle, eval_train_metric)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mtparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0mcvbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0meval_train_metric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mcvbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[1;32m   1712\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1713\u001b[0m             _safe_call(_LIB.LGBM_BoosterCreate(\n\u001b[0;32m-> 1714\u001b[0;31m                 \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1715\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m                 ctypes.byref(self.handle)))\n",
      "\u001b[0;32m/opt/conda/envs/python3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1072\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1075\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Label should not be None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_InnerPredictor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predictor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predictor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mget_label\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1459\u001b[0m         \"\"\"\n\u001b[1;32m   1460\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1461\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_field\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1462\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mget_field\u001b[0;34m(self, field_name)\u001b[0m\n\u001b[1;32m   1261\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcint32_array_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPOINTER\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_out_len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mC_API_DTYPE_FLOAT32\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcfloat32_array_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPOINTER\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_out_len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1264\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mC_API_DTYPE_FLOAT64\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcfloat64_array_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPOINTER\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_double\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_out_len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mcfloat32_array_to_numpy\u001b[0;34m(cptr, length)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;34m\"\"\"Convert a ctypes float pointer array to a numpy array.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPOINTER\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromiter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected float pointer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import optuna.integration.lightgbm as lgb\n",
    "\n",
    "\n",
    "dtrain = lgb.Dataset(X_15, label=y)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"verbosity\": -1,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "}\n",
    "\n",
    "tuner = lgb.LightGBMTunerCV(\n",
    "    params, dtrain, verbose_eval=0, early_stopping_rounds=100, folds=KFold(n_splits=3), show_progress_bar=True\n",
    ")\n",
    "\n",
    "tuner.run()\n",
    "\n",
    "print(\"Best score:\", tuner.best_score)\n",
    "best_params = tuner.best_params\n",
    "print(\"Best params:\", best_params)\n",
    "print(\"  Params: \")\n",
    "for key, value in best_params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
